{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Group Project/Final\n",
    "## Kaggle Competition: Random Acts of Pizza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members:<br>\n",
    "Daniel Elkin<br>\n",
    "Mark Gin\n",
    "\n",
    "Project Prompt:<br>\n",
    "People post pizza requests on Reddit<br>\n",
    "Build 2-class classifier<br>\n",
    "Classify whether post will get pizza<br>\n",
    "Practice mining features from text<br>\n",
    "\n",
    "Reference links:\n",
    " - https://www.kaggle.com/c/random-acts-of-pizza\n",
    " - http://cs.stanford.edu/~althoff/raop-dataset/\n",
    "\n",
    "Data Set:<br>\n",
    "This training dataset contains a collection of 5671 textual requests for pizza from the Reddit community \"Random Acts of Pizza\" together with their outcome (successful/unsuccessful) and meta-data.\n",
    "\n",
    "We will split the dataset into:\n",
    " - 25% for development\n",
    " - 75% for training\n",
    "\n",
    "A separate dataset file was provided for testing purposes, of which we do not have the labels as to whether or not a pizza was received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bobo/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Bobo/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "df_train = pd.read_json('train.json')\n",
    "df_test = pd.read_json('test.json')\n",
    "\n",
    "# drop the target column from the data and use it for the labels\n",
    "classification_column_name = 'requester_received_pizza'\n",
    "\n",
    "train_data = df_train.drop([classification_column_name], axis=1)\n",
    "train_labels = df_train[classification_column_name]\n",
    "\n",
    "# use twenty-five percent of the training data for a dev data set\n",
    "# note that we cannot use the test data set here, because we are not given their labels\n",
    "train_data, dev_data, train_labels, dev_labels = train_test_split(train_data, train_labels, random_state=42)\n",
    "\n",
    "# global dictionary of accuracies so we can plot our progress\n",
    "accuracy_dict = {}\n",
    "# keeping a list of model modification names, so we can plot them in a particular order\n",
    "modification = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will be parsing the message body of each pizza request to utilize as features for our models, we will create term-frequency matricies of the text to use in our models as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# debug function used to print the vocabularies into a text file\n",
    "def output_file(output_name, output_list):\n",
    "    with open(output_name, 'w') as output:\n",
    "        for i in output_list:\n",
    "            output.write(i.encode('UTF-8') + \"\\n\")\n",
    "\n",
    "def decimal_to_percent(decimal):\n",
    "    return round(decimal * 100, 2)\n",
    "\n",
    "def basic_vectorizer():\n",
    "    ''' Construct term-frequency matrices for use in models '''\n",
    "    \n",
    "    # use title and text of the post\n",
    "    text_column = 'request_text'\n",
    "    train_text = train_data['request_title'] + train_data[text_column]\n",
    "    dev_text = dev_data['request_title'] + dev_data[text_column]\n",
    "#    train_text = train_data[text_column]\n",
    "#    dev_text = dev_data[text_column]\n",
    "\n",
    "    # construct the term-frequency count matrix\n",
    "    tf_vect = CountVectorizer()\n",
    "    tf_train = tf_vect.fit_transform(train_text)\n",
    "    tf_dev = tf_vect.transform(dev_text)\n",
    "    \n",
    "    #output_file(\"basic_vocab.txt\", tf_vect.get_feature_names())\n",
    "    \n",
    "    return (tf_train, tf_dev)\n",
    "\n",
    "(tf_train, tf_dev) = basic_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will train basic models, without tuning, for each candidate learning model:\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Decision Tree\n",
    "  \n",
    "We will train and find the accuracies of each model.  This will give us a general idea of which learning models may be most successful and can build upon them from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, tf_train, train_labels, tf_dev, dev_labels):\n",
    "    ''' Train and score a model'''\n",
    "    clf = model\n",
    "    clf.fit(tf_train, train_labels)\n",
    "    \n",
    "    # return the accuracy and F1 scores\n",
    "    accuracy = clf.score(tf_dev, dev_labels) \n",
    "    predicted = clf.predict(tf_dev)\n",
    "    f1_score = metrics.f1_score(predicted, dev_labels, average=None)\n",
    "\n",
    "    return accuracy, f1_score\n",
    "\n",
    "def print_model_scores(model_type, accuracy, f1_score):\n",
    "    ''' Print the accuracy and f1 scores '''\n",
    "    \n",
    "    print 'The accuracy of {} model is {}%'.format(model_type, decimal_to_percent(accuracy))\n",
    "    print 'The F1 scores are: False: {}\\n                    True: {}'.format(*[decimal_to_percent(score) for score in f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression model is 69.21%\n",
      "The F1 scores are: False: 80.48\n",
      "                    True: 27.17\n",
      "The accuracy of Naive Bayes model is 71.98%\n",
      "The F1 scores are: False: 82.8\n",
      "                    True: 24.53\n",
      "The accuracy of Decision Tree model is 65.74%\n",
      "The F1 scores are: False: 77.59\n",
      "                    True: 27.31\n"
     ]
    }
   ],
   "source": [
    "# train basic models to gauge baseline performance of the models\n",
    "# Logisitc Regression\n",
    "# Naive Bayes\n",
    "# Decision Tree\n",
    "basic_lr = LogisticRegression()\n",
    "basic_nb = BernoulliNB()\n",
    "basic_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({0: 'Basic'})\n",
    "accuracy_dict['Basic'] = {}\n",
    "for model, model_name in [(basic_lr, 'Logistic Regression'), (basic_nb, 'Naive Bayes'),\n",
    "                  (basic_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model, tf_train, train_labels, tf_dev, dev_labels)\n",
    "    # first time adding accuracies to dictionary\n",
    "    accuracy_dict['Basic'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Preprocessing\n",
    "Let's attempt to build upon our basic models by introducing preprocessing algorithms for our word vocabulary vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_with_preprocessor(preprocessor_func, ngram=(1,1), mindf=1):\n",
    "    ''' Construct term-frequency matrices for use in models '''\n",
    "    \n",
    "    # use title and text of the post\n",
    "    text_column = 'request_text'\n",
    "    train_text = train_data['request_title'] + train_data[text_column]\n",
    "    dev_text = dev_data['request_title'] + dev_data[text_column]\n",
    "\n",
    "    # construct the term-frequency count matrix\n",
    "    tf_vect = CountVectorizer(preprocessor=preprocessor_func,\n",
    "                              ngram_range=ngram,\n",
    "                              min_df=mindf)\n",
    "    tf = tf_vect.fit(train_text)\n",
    "    \n",
    "    # make the matrices global variables for convenience?\n",
    "    tf_train_pp = tf.transform(train_text)\n",
    "    tf_dev_pp = tf.transform(dev_text)\n",
    "    \n",
    "    #output_file(\"porter.txt\", tf_vect.get_feature_names())\n",
    "    #output_file(\"composite.txt\", tf_vect.get_feature_names())\n",
    "    \n",
    "    return (tf_train_pp, tf_dev_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use porter-stemming algorithm to generalize words in the messages\n",
    "# https://tartarus.org/martin/PorterStemmer/def.txt\n",
    "def porter_stemming(s):\n",
    "    # create a new empty string, since s is the entire message not a single word\n",
    "    new_s = \"\"\n",
    "    \n",
    "    # iterate through each word in space delimited string\n",
    "    for w in s.split():\n",
    "        # calculate the measure, which is the number of vowel to consanant transitions\n",
    "        m_cnt = 0\n",
    "        if (re.search('^[^aeiou]*(([aeiou]+[^aeiou]+)+)[aeiou]*$', w)):\n",
    "            measure_match = re.match('^[^aeiou]*(([aeiou]+[^aeiou]+)+)[aeiou]*$', w)\n",
    "            # split on vowels to count number of transitions\n",
    "            consanant_groups = re.split('[aeiou]+', measure_match.group(1))\n",
    "            m_cnt = len(consanant_groups) - 1\n",
    "        \n",
    "        # Step 1a of porter stemming\n",
    "        if re.search('sses$', w):\n",
    "            w = re.sub('sses$', 'ss', w)\n",
    "        elif re.search('ies$', w):\n",
    "            w = re.sub('ies$', 'i', w)\n",
    "        elif re.search('ss$', w):\n",
    "            w = re.sub('ss$', 'i', w)\n",
    "        elif re.search('s$', w):\n",
    "            w = re.sub('s$', '', w)\n",
    "        # Step 1b\n",
    "        # Porter-Stemming says this should be m_cnt > 0, but doesn't\n",
    "        # even match their own examples, tweaked to 1 and got slightly better performance\n",
    "#        if (m_cnt > 1 and re.search('eed$', w)):\n",
    "#            w = re.sub('eed$', 'ee', w)\n",
    "#        elif (re.search('.*[aeiou].*(ed|ing)$', w)):\n",
    "#            w = re.sub('(ed|ing)$', '', w)\n",
    "#            # if the second or third rule of 1b is successful, we also\n",
    "#            if (re.search('(at|bl|iz)$', w)):\n",
    "#                w += 'e'\n",
    "#            # ends in double consanant, but no l s or z\n",
    "#            elif (re.search('.*([^aeiou])([^aeiou])$', w)) :\n",
    "#                m = re.match('(.*)([^aeiou])([^aeiou])$', w)\n",
    "#                if (m.group(3) == m.group(2) and\n",
    "#                    m.group(3) != 'l' and\n",
    "#                    m.group(3) != 's' and\n",
    "#                    m.group(3) != 'z') :\n",
    "#                    w = m.group(1) + m.group(2)\n",
    "#            # measure at least one and ends in cvc\n",
    "#            # but second c is not W,X,Y\n",
    "#            elif (m_cnt == 1 and re.search('^.*[^aeiou][aeiou][^aeiouwxy]$', w)) :\n",
    "#                w = re.sub('[^aeiouwxy]$', 'e', w)\n",
    "        # Step 1c\n",
    "        if (re.search('.*[aeiou].*y$', w)) :\n",
    "            w = re.sub('y$', 'i', w)\n",
    "        # Step 2\n",
    "        if (m_cnt > 0) :\n",
    "            if (re.search('ational$', w)) :\n",
    "                w = re.sub('ational$', 'ate', w)\n",
    "            elif (re.search('tional$', w)) :\n",
    "                w = re.sub('tional$', 'tion', w)\n",
    "            elif (re.search('enci$', w)) :\n",
    "                w = re.sub('enci$', 'ence', w)\n",
    "            elif (re.search('anci$', w)) :\n",
    "                w = re.sub('anci$', 'ance', w)\n",
    "            elif (re.search('izer$', w)) :\n",
    "                w = re.sub('izer$', 'ize', w)\n",
    "            elif (re.search('abli$', w)) :\n",
    "                w = re.sub('abli$', 'able', w)\n",
    "            elif (re.search('alli$', w)) :\n",
    "                w = re.sub('alli$', 'al', w)\n",
    "            elif (re.search('entli$', w)) :\n",
    "                w = re.sub('entli$', 'ent', w)\n",
    "            elif (re.search('eli$', w)) :\n",
    "                w = re.sub('eli$', 'e', w)\n",
    "            elif (re.search('ousli$', w)) :\n",
    "                w = re.sub('ousli$', 'ous', w)\n",
    "            elif (re.search('ization$', w)) :\n",
    "                w = re.sub('ization$', 'ize', w)\n",
    "            elif (re.search('(ation|ator)$', w)) :\n",
    "                w = re.sub('(ation|ator)$', 'ate', w)\n",
    "            elif (re.search('alism$', w)) :\n",
    "                w = re.sub('alism$', 'al', w)\n",
    "            elif (re.search('iveness$', w)) :\n",
    "                w = re.sub('iveness$', 'ive', w)\n",
    "            elif (re.search('fulness$', w)) :\n",
    "                w = re.sub('fulness$', 'ful', w)\n",
    "            elif (re.search('ousness$', w)) :\n",
    "                w = re.sub('ousness$', 'ous', w)\n",
    "            elif (re.search('aliti$', w)) :\n",
    "                w = re.sub('aliti$', 'al', w)\n",
    "            elif (re.search('iviti$', w)) :\n",
    "                w = re.sub('iviti$', 'ive', w)\n",
    "            elif (re.search('biliti$', w)) :\n",
    "                w = re.sub('biliti$', 'ble', w)\n",
    "        # Step 3\n",
    "        if (m_cnt > 0) :\n",
    "            if (re.search('icate$', w)) :\n",
    "                w = re.sub('icate$', 'ic', w)\n",
    "            elif (re.search('ative$', w)) :\n",
    "                w = re.sub('ative$', '', w)\n",
    "            elif (re.search('alize$', w)) :\n",
    "                w = re.sub('alize$', 'al', w)\n",
    "            elif (re.search('iciti$', w)) :\n",
    "                w = re.sub('iciti$', 'ic', w)\n",
    "            elif (re.search('ical$', w)) :\n",
    "                w = re.sub('ical$', 'ic', w)\n",
    "            elif (re.search('ful$', w)) :\n",
    "                w = re.sub('ful$', '', w)\n",
    "            elif (re.search('ness$', w)) :\n",
    "                w = re.sub('ness$', '', w)\n",
    "        # Step 4\n",
    "        if (m_cnt > 1) :\n",
    "            if (re.search('al$', w)) :\n",
    "                w = re.sub('al$', '', w)\n",
    "            elif (re.search('ance$', w)) :\n",
    "                w = re.sub('ance$', '', w)\n",
    "            elif (re.search('ence$', w)) :\n",
    "                w = re.sub('ence$', '', w)\n",
    "            elif (re.search('er$', w)) :\n",
    "                w = re.sub('er$', '', w)\n",
    "            elif (re.search('ic$', w)) :\n",
    "                w = re.sub('ic$', '', w)\n",
    "            elif (re.search('able$', w)) :\n",
    "                w = re.sub('able$', '', w)\n",
    "            elif (re.search('ible$', w)) :\n",
    "                w = re.sub('ible$', '', w)\n",
    "            elif (re.search('ant$', w)) :\n",
    "                w = re.sub('ant$', '', w)\n",
    "            elif (re.search('ement$', w)) :\n",
    "                w = re.sub('ement$', '', w)\n",
    "            elif (re.search('ent$', w)) :\n",
    "                w = re.sub('ent$', '', w)\n",
    "            elif (m_cnt > 1 and re.search('[s|t]ion$', w)) :\n",
    "                w = re.sub('[s|t]ion$', '', w)\n",
    "            elif (re.search('ou$', w)) :\n",
    "                w = re.sub('ou$', '', w)\n",
    "            elif (re.search('ism$', w)) :\n",
    "                w = re.sub('ism$', '', w)\n",
    "            elif (re.search('ate$', w)) :\n",
    "                w = re.sub('ate$', '', w)\n",
    "            elif (re.search('iti$', w)) :\n",
    "                w = re.sub('iti$', '', w)\n",
    "            elif (re.search('ous$', w)) :\n",
    "                w = re.sub('ous$', '', w)\n",
    "            elif (re.search('ive$', w)) :\n",
    "                w = re.sub('ive$', '', w)\n",
    "            elif (re.search('ize$', w)) :\n",
    "                w = re.sub('ize$', '', w)\n",
    "        # Step 5a\n",
    "        if (m_cnt > 1 and re.search('e$', w)) :\n",
    "            w = re.sub('e$', '', w)\n",
    "        # measure at least one and ends in cvc\n",
    "        # but second c is not W,X,Y\n",
    "        elif (m_cnt == 1 and not re.search('^[^aeiou][aeiou][^aeiouwxy]e$', w)) :\n",
    "            w = re.sub('e$', '', w)\n",
    "        # Step 5b\n",
    "        if (m_cnt > 1 and re.search('.*ll$', w)):\n",
    "            w = re.sub('l$', '', w)\n",
    "        # end of porter stemming\n",
    "        # attach the word back to the new string\n",
    "        new_s += (\" \" + w)\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stopword_preprocessor(s):    \n",
    "    # remove \"stop\" words which bear no significant meaning in most contexts\n",
    "    s = re.sub(' ?the ', r' ', s)\n",
    "    s = re.sub(' ?who ', r' ', s)\n",
    "    s = re.sub(' ?what ', r' ', s)\n",
    "    s = re.sub(' ?them ', r' ', s)\n",
    "    s = re.sub(' ?my ', r' ', s)\n",
    "    s = re.sub(' ?our ', r' ', s)\n",
    "    s = re.sub(' ?this ', r' ', s)\n",
    "    s = re.sub(' ?that ', r' ', s)\n",
    "    s = re.sub(' ?which ', r' ', s)\n",
    "    s = re.sub(' ?why ', r' ', s)\n",
    "    s = re.sub(' ?me ', r' ', s)\n",
    "    #s = re.sub(' ?i ', r' ', s)\n",
    "    #s = re.sub(' ?us ', r' ', s)\n",
    "    #s = re.sub(' ?you ', r' ', s)\n",
    "    s = re.sub(' ?they ', r' ', s)\n",
    "    s = re.sub(' ?where ', r' ', s)\n",
    "    s = re.sub(' ?and ', r' ', s)\n",
    "    s = re.sub(' ?for ', r' ', s)\n",
    "    s = re.sub(' ?his ', r' ', s)\n",
    "    s = re.sub(' ?her ', r' ', s)\n",
    "    s = re.sub(' ?to ', r' ', s)\n",
    "    #s = re.sub(' ?of ', r' ', s)\n",
    "    \n",
    "    # let's also get rid of 'request' and 'pizza' since they show up frequently in titles\n",
    "    s = re.sub('request', r'', s)\n",
    "    s = re.sub('pizza', r'', s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic string preprocessor:\n",
    "# lowercases all text, removes, digits and special characters\n",
    "def basic_preprocessor(s):\n",
    "    # make everything lowercase\n",
    "    s = s.lower()\n",
    "    \n",
    "    # eliminate consecutive digits\n",
    "    s = re.sub('([0-9])[0-9]+', r'\\1', s)\n",
    "    \n",
    "    # eliminate all digits\n",
    "    #s = re.sub('[0-9]+', r'', s)\n",
    "    \n",
    "    # eliminate special characters, except hyphens\n",
    "    s = re.sub('[^A-Za-z0-9\\s\\-]+', ' ', s)\n",
    "    \n",
    "    # add a space between consecutive numbers/alpha\n",
    "    s = re.sub('([0-9])([a-z])', '\\1 \\2', s)\n",
    "    s = re.sub('([a-z])([0-9])', '\\1 \\2', s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses the other preprocessors already written above\n",
    "# to form a composite preprocessor\n",
    "def composite_preprocessor(s):\n",
    "    s = basic_preprocessor(s)\n",
    "    s = stopword_preprocessor(s)\n",
    "    #s = porter_stemming(s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed different preprocessors with different functionalities:\n",
    "- Basic Preprocessor\n",
    " - Lower case text, removes consecutive digits\n",
    "- Stopword Preprocessor\n",
    " - Removes common, non contextual stopwords (the, that, and... etc)\n",
    "- Porter-Stemming Preprocessor\n",
    " - Advanced preprocessing of vocabulary, suffix removal\n",
    " - Example: learning -> learn\n",
    "\n",
    "We retrained new basic models, this time we use an updated vocabulary based on our vectorizer preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression model is 70.1%\n",
      "The F1 scores are: False: 81.24\n",
      "                    True: 26.34\n",
      "The accuracy of Naive Bayes model is 71.88%\n",
      "The F1 scores are: False: 82.81\n",
      "                    True: 22.83\n",
      "The accuracy of Decision Tree model is 65.64%\n",
      "The F1 scores are: False: 77.74\n",
      "                    True: 24.73\n"
     ]
    }
   ],
   "source": [
    "(tf_pp_train, tf_pp_dev) = vectorize_with_preprocessor(composite_preprocessor)\n",
    "    \n",
    "# train basic models to gauge baseline performance of the models\n",
    "# Logisitc Regression\n",
    "# Naive Bayes\n",
    "# Decision Tree\n",
    "basic_pp_cv_lr = LogisticRegression()\n",
    "basic_pp_cv_nb = BernoulliNB()\n",
    "basic_pp_cv_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({1:'PP Vocab'})\n",
    "accuracy_dict['PP Vocab'] = {}\n",
    "for model, model_name in [(basic_pp_cv_lr, 'Logistic Regression'), (basic_pp_cv_nb, 'Naive Bayes'),\n",
    "                  (basic_pp_cv_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model, tf_pp_train, train_labels,\n",
    "                                                  tf_pp_dev, dev_labels)\n",
    "    accuracy_dict['PP Vocab'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our testing, we found the best results by compositing our basic preprocessor with the stopword preprocessor.  The Porter-Stemming preprocessor seemed to actually have an adverse impact in accuracy, albeit, marginal.\n",
    "\n",
    "Using the composite preprocessor (basic and stopword), the accuracy of for our models changed:\n",
    "- Logistic Regression model from 69.21% to 70.1%\n",
    "- Naive Bayes model from 71.98% to 71.88%\n",
    "- Decision Tree model from 67.72% to 64.75%\n",
    "\n",
    "Although the addition of preprocessing had only marginal impacts to Logistic Regression and Naive Bayes, in our dataset, it appears to have improved Logistic Regression, if only slightly and had a negative affect for Naive Bayes, also only slightly.  Decision Tree modeling was more adversely affected by the introduction of preprocessing.\n",
    "\n",
    "Overall, Naive Bayes appears to be performing better than the Logistic Regression and Decision Tree models, although only about 2% better over the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression model is 74.85%\n",
      "The F1 scores are: False: 85.45\n",
      "                    True: 7.3\n",
      "The accuracy of Naive Bayes model is 71.88%\n",
      "The F1 scores are: False: 82.81\n",
      "                    True: 22.83\n",
      "The accuracy of Decision Tree model is 62.77%\n",
      "The F1 scores are: False: 75.17\n",
      "                    True: 25.69\n"
     ]
    }
   ],
   "source": [
    "# Vectorize textual data with TF-IDF transformation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_vectorizer(preprocessor_func, ngram=(1,1)):\n",
    "    # use title and text of the post\n",
    "    text_column = 'request_text'\n",
    "    train_text = train_data['request_title'] + train_data[text_column]\n",
    "    dev_text = dev_data['request_title'] + dev_data[text_column]\n",
    "\n",
    "    # construct the term-frequency count matrix\n",
    "    tfidf_vect = TfidfVectorizer(preprocessor=preprocessor_func, ngram_range=ngram)\n",
    "    tfidf = tfidf_vect.fit(train_text)\n",
    "    \n",
    "    tfidf_train = tfidf_vect.transform(train_text)\n",
    "    tfidf_dev = tfidf_vect.transform(dev_text)\n",
    "    \n",
    "    return (tfidf_train, tfidf_dev)\n",
    "\n",
    "(tfidf_pp_train, tfidf_pp_dev) = tfidf_vectorizer(composite_preprocessor)\n",
    "\n",
    "basic_pp_tfidf_lr = LogisticRegression()\n",
    "basic_pp_tfidf_nb = BernoulliNB()\n",
    "basic_pp_tfidf_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({2: 'TF-IDF Vocab'})\n",
    "accuracy_dict['TF-IDF Vocab'] = {}\n",
    "for model, model_name in [(basic_pp_tfidf_lr, 'Logistic Regression'),\n",
    "                          (basic_pp_tfidf_nb, 'Naive Bayes'),\n",
    "                          (basic_pp_tfidf_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model,\n",
    "                                                  tfidf_pp_train, train_labels,\n",
    "                                                  tfidf_pp_dev, dev_labels)\n",
    "    accuracy_dict['TF-IDF Vocab'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempted to also try a TF-IDF (Term Frequncy) vectorizer for our training vocabulary to see if using a different vectorizer method would bear significant improvment to our models.  We found a good improvment in overall accuracy of our Logistic Regression model but did not find any signifcant differences in applying a different vectorizer to Naive Bayes whereas  Decision Tree model was adversely affected:\n",
    " - Logistic Regression 70.1 to 74.85\n",
    " - Naive Bayes 71.88 to 71.88\n",
    " - Decision Tree 64.75 to 62.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional potential improvment to both models is to modify our count vectorizer to include bi-gram text, as opposed to uni-gram text which is currently being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Count Vectorizer and bi-gram vocabulary:\n",
      "The accuracy of Logistic Regression model is 70.59%\n",
      "The F1 scores are: False: 82.03\n",
      "                    True: 19.07\n",
      "The accuracy of Naive Bayes model is 73.96%\n",
      "The F1 scores are: False: 85.0\n",
      "                    True: 1.5\n",
      "The accuracy of Decision Tree model is 68.71%\n",
      "The F1 scores are: False: 80.15\n",
      "                    True: 26.17\n",
      "Using TF-IDF Vectorizer and bi-gram vocabulary:\n",
      "The accuracy of Logistic Regression model is 74.46%\n",
      "The F1 scores are: False: 85.34\n",
      "                    True: 0.77\n",
      "The accuracy of Naive Bayes model is 73.96%\n",
      "The F1 scores are: False: 85.0\n",
      "                    True: 1.5\n",
      "The accuracy of Decision Tree model is 62.57%\n",
      "The F1 scores are: False: 74.7\n",
      "                    True: 28.14\n"
     ]
    }
   ],
   "source": [
    "print \"Using Count Vectorizer and bi-gram vocabulary:\"\n",
    "bi_gram = (1,2)\n",
    "(tf_bi_train, tf_bi_dev) = vectorize_with_preprocessor(composite_preprocessor, bi_gram)\n",
    "    \n",
    "# train basic models to gauge baseline performance of the models\n",
    "# Logisitc Regression\n",
    "# Naive Bayes\n",
    "# Decision Tree\n",
    "basic_bi_lr = LogisticRegression()\n",
    "basic_bi_nb = BernoulliNB()\n",
    "basic_bi_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({3: 'CV Bi-gram'})\n",
    "accuracy_dict['CV Bi-gram'] = {}\n",
    "for model, model_name in [(basic_bi_lr, 'Logistic Regression'), (basic_bi_nb, 'Naive Bayes'),\n",
    "                  (basic_bi_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model, tf_bi_train, train_labels,\n",
    "                                                  tf_bi_dev, dev_labels)\n",
    "    accuracy_dict['CV Bi-gram'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)\n",
    "    \n",
    "print \"Using TF-IDF Vectorizer and bi-gram vocabulary:\"\n",
    "(tfidf_bi_train, tfidf_bi_dev) = tfidf_vectorizer(composite_preprocessor, bi_gram)\n",
    "\n",
    "basic_tfidf_bi_lr = LogisticRegression()\n",
    "basic_tfidf_bi_nb = BernoulliNB()\n",
    "basic_tfidf_bi_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({4: 'TF-IDF Bi-gram'})\n",
    "accuracy_dict['TF-IDF Bi-gram'] = {}\n",
    "for model, model_name in [(basic_tfidf_bi_lr, 'Logistic Regression'),\n",
    "                          (basic_tfidf_bi_nb, 'Naive Bayes'),\n",
    "                          (basic_tfidf_bi_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model,\n",
    "                                                  tfidf_bi_train, train_labels,\n",
    "                                                  tfidf_bi_dev, dev_labels)\n",
    "    accuracy_dict['TF-IDF Bi-gram'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bi-gram vocabularies, using both the Count and TF-IDF vectorizers had mixed results, with marginal improvments and degredation in overall accuracy for various models.  It should also be noted that when there was improvment, the F1 score for sucessful pizza requests dropped significantly, which means our models are likely over-fitting/over-predicting the false class which is proportinately larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Model Hyperparameters\n",
    "We will attempt to tune a basic model with preprocessed vocabulary by gridsearching over various hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'C': 0.001}\n",
      "The accuracy of Tuned Logistic Regression with CV model is 74.55%\n",
      "The F1 scores are: False: 85.42\n",
      "                    True: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bobo/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'C': 0.001}\n",
      "The accuracy of Tuned Logistic Regression with TF-IDF model is 74.55%\n",
      "The F1 scores are: False: 85.42\n",
      "                    True: 0.0\n",
      "The accuracy of Manual Tuned Logistic Regression with CV model is 71.88%\n",
      "The F1 scores are: False: 82.95\n",
      "                    True: 19.77\n",
      "The accuracy of Manual Tuned Logistic Regression with TF-IDF model is 72.38%\n",
      "The F1 scores are: False: 83.38\n",
      "                    True: 18.18\n"
     ]
    }
   ],
   "source": [
    "# generic grid search which can field different models and hyperparameters\n",
    "# and output the best results\n",
    "def gridsearch_model(model, parameters, tf_dev, dev_labels): \n",
    "    gridsearch = GridSearchCV(estimator=model,\n",
    "                              param_grid=parameters)\n",
    "    gridsearch.fit(tf_dev, dev_labels)\n",
    "    \n",
    "    print \"Best parameters:\"\n",
    "    print gridsearch.best_params_\n",
    "    return gridsearch\n",
    "    \n",
    "# c_values for logistic regression\n",
    "c_values = {'C': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0,\n",
    "                  5.0, 10.0, 15.0, 20.0, 25.0, 50.0, 75.0, 100.0]}\n",
    "\n",
    "# logistic regression tuning using the preprocessed vocabulary model\n",
    "lr_gs = gridsearch_model(basic_pp_cv_lr, c_values, tf_pp_dev, dev_labels)\n",
    "\n",
    "# use optimal parameters\n",
    "tuned_lr = LogisticRegression(C=lr_gs.best_params_['C'])\n",
    "tuned_lr.fit(tf_pp_train, train_labels)\n",
    "lr_accuracy = tuned_lr.score(tf_pp_dev, dev_labels) \n",
    "lr_predicted = tuned_lr.predict(tf_pp_dev)\n",
    "lr_f1_score = metrics.f1_score(lr_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Tuned Logistic Regression with CV\", lr_accuracy, lr_f1_score)\n",
    "\n",
    "# grid search again, this time using our preprocessed TF-IDF vocabulary\n",
    "lr_gs = gridsearch_model(basic_pp_tfidf_lr, c_values, tfidf_pp_dev, dev_labels)\n",
    "\n",
    "# use optimal parameters\n",
    "tuned_tfidf_lr = LogisticRegression(C=lr_gs.best_params_['C'])\n",
    "tuned_tfidf_lr.fit(tfidf_pp_train, train_labels)\n",
    "lr_tfidf_accuracy = tuned_tfidf_lr.score(tfidf_pp_dev, dev_labels) \n",
    "lr_tfidf_predicted = tuned_tfidf_lr.predict(tfidf_pp_dev)\n",
    "lr_tfidf_f1_score = metrics.f1_score(lr_tfidf_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Tuned Logistic Regression with TF-IDF\", lr_tfidf_accuracy, lr_tfidf_f1_score)\n",
    "\n",
    "# manual tuning parameters with preprocessed CV\n",
    "manual_lr = LogisticRegression(C=0.15)\n",
    "manual_lr.fit(tf_pp_train, train_labels)\n",
    "manual_lr_accuracy = manual_lr.score(tf_pp_dev, dev_labels) \n",
    "manual_lr_predicted = manual_lr.predict(tf_pp_dev)\n",
    "manual_lr_f1_score = metrics.f1_score(manual_lr_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Manual Tuned Logistic Regression with CV\", manual_lr_accuracy, manual_lr_f1_score)\n",
    "\n",
    "# manual tuning parameters with preprocessed TF-IDF\n",
    "manual_tfidf_lr = LogisticRegression(C=5)\n",
    "manual_tfidf_lr.fit(tfidf_pp_train, train_labels)\n",
    "manual_lr_tfidf_accuracy = manual_tfidf_lr.score(tfidf_pp_dev, dev_labels) \n",
    "manual_lr_tfidf_predicted = manual_tfidf_lr.predict(tfidf_pp_dev)\n",
    "manual_lr_tfidf_f1_score = metrics.f1_score(manual_lr_tfidf_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Manual Tuned Logistic Regression with TF-IDF\", manual_lr_tfidf_accuracy, manual_lr_tfidf_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'alpha': 0.95}\n",
      "The accuracy of Tuned Naive Bayes with CV model is 71.58%\n",
      "The F1 scores are: False: 82.49\n",
      "                    True: 24.67\n",
      "Best parameters:\n",
      "{'alpha': 0.95}\n",
      "The accuracy of Tuned Naive Bayes with TF-IDF model is 71.58%\n",
      "The F1 scores are: False: 85.42\n",
      "                    True: 0.0\n",
      "The accuracy of Manual Tuned Naive Bayes with CV model is 72.67%\n",
      "The F1 scores are: False: 83.59\n",
      "                    True: 18.34\n",
      "The accuracy of Manual Tuned Naive Bayes with TF-IDF model is 72.38%\n",
      "The F1 scores are: False: 83.38\n",
      "                    True: 18.18\n"
     ]
    }
   ],
   "source": [
    "# naive bayes tuning\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0,]}\n",
    "gridsearch_model(basic_pp_cv_nb, params, tf_pp_dev, dev_labels)\n",
    "\n",
    "tuned_nb = BernoulliNB(alpha=0.85)\n",
    "tuned_nb.fit(tf_pp_train, train_labels)\n",
    "nb_accuracy = tuned_nb.score(tf_pp_dev, dev_labels)\n",
    "nb_predicted = tuned_nb.predict(tf_pp_dev)\n",
    "nb_f1_score = metrics.f1_score(nb_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Tuned Naive Bayes with CV\", nb_accuracy, nb_f1_score)\n",
    "\n",
    "# TF-IDF vocabulary w/ Naive Bayes tuning\n",
    "gridsearch_model(basic_pp_tfidf_nb, params, tf_pp_dev, dev_labels)\n",
    "# use optimal parameters\n",
    "tuned_tfidf_nb = BernoulliNB(alpha=0.85)\n",
    "tuned_tfidf_nb.fit(tfidf_pp_train, train_labels)\n",
    "nb_tfidf_accuracy = tuned_tfidf_nb.score(tfidf_pp_dev, dev_labels) \n",
    "nb_tfidf_predicted = tuned_tfidf_lr.predict(tfidf_pp_dev)\n",
    "nb_tfidf_f1_score = metrics.f1_score(nb_tfidf_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Tuned Naive Bayes with TF-IDF\", nb_tfidf_accuracy, nb_tfidf_f1_score)\n",
    "\n",
    "# manual tuning parameters with preprocessed CV\n",
    "manual_nb = LogisticRegression(C=0.1)\n",
    "manual_nb.fit(tf_pp_train, train_labels)\n",
    "manual_nb_accuracy = manual_nb.score(tf_pp_dev, dev_labels) \n",
    "manual_nb_predicted = manual_nb.predict(tf_pp_dev)\n",
    "manual_nb_f1_score = metrics.f1_score(manual_nb_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Manual Tuned Naive Bayes with CV\", manual_nb_accuracy, manual_nb_f1_score)\n",
    "\n",
    "# manual tuning parameters with preprocessed TF-IDF\n",
    "manual_tfidf_nb = LogisticRegression(C=5)\n",
    "manual_tfidf_nb.fit(tfidf_pp_train, train_labels)\n",
    "manual_nb_tfidf_accuracy = manual_tfidf_nb.score(tfidf_pp_dev, dev_labels) \n",
    "manual_nb_tfidf_predicted = manual_tfidf_nb.predict(tfidf_pp_dev)\n",
    "manual_nb_tfidf_f1_score = metrics.f1_score(manual_nb_tfidf_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Manual Tuned Naive Bayes with TF-IDF\", manual_nb_tfidf_accuracy, manual_nb_tfidf_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, while using grid search we were able to optimize hyperparameter values, C and alpha, for Logistic Regression and Naive Bayes, respectively, that improved overall accuracy of the models.  However, using these optimize values provided very low F1 scores and low accuracy for our two categories of prediction (True = Pizza Received/False = Pizza Not Received).  What this means, is that our gridsearch tuned models are simply predicting everything to be false in order to optimize overall accuracy.\n",
    "\n",
    "Trial and error proved to be more effective in improving overall accuracy without completely sacrificing our F1 scores for our categories.\n",
    "\n",
    "From this information, it is possible there is a class imbalance in our training data and the model is merely always guessing False/unsuccessful pizza requests to obtain a higher accuracy.  If there is a class imbalance in our training data, it may be difficult for the model to distinguish between sucessful and unsucessful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance/Weighting\n",
    "Based on the information we learned while attempting to tune our models, we will investigate and attempt to account for a class imbalance in our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2293\n",
      "1 737\n"
     ]
    }
   ],
   "source": [
    "# doing some exploration to find out if there is a class imbalance in our training data\n",
    "# by counting the outcome classes in our training set\n",
    "def class_counts():\n",
    "    counts = [0, 0]\n",
    "    for i in train_labels:\n",
    "        counts[i] += 1\n",
    "    \n",
    "    for i in range(len(counts)):\n",
    "        print i, counts[i]\n",
    "        \n",
    "class_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe from our class counting that there is indeed some weight imbalance in our training set.   There are far more classes in the unsucessful requests compared to the sucessful requests, roughly 3 to 1, in the favor of unsuccessful requests.  We can use this knowledge to weight our classes for training to improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Weighed Logistic Regression model is 65.94%\n",
      "The F1 scores are: False: 76.97\n",
      "                    True: 34.6\n"
     ]
    }
   ],
   "source": [
    "# There is some class imbalance, so lets try weighting based on the ratio of classes\n",
    "weight_dict = {0: 0.33, 1: .67}\n",
    "lr_weight = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "lr_weight.fit(tf_pp_train, train_labels)\n",
    "lrw_accuracy = lr_weight.score(tf_pp_dev, dev_labels) \n",
    "lrw_predicted = lr_weight.predict(tf_pp_dev)\n",
    "lrw_f1_score = metrics.f1_score(lrw_predicted, dev_labels, average=None)\n",
    "print_model_scores(\"Weighed Logistic Regression\", lrw_accuracy, lrw_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We experimented with manual weighting adjustment, but found that using the 'balanced' weighting typing showed the greatest improvement to the F1 accuracy for the \"True' class, but our overall accuracy suffers significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Other Features\n",
    "\n",
    "Next we will experiment with applying other features from the dataset.  We generate a tabular output showing the updated accuracy and F1 scores for applying a single feature in addition to our vocabulary for analysis.  From this, we can continue to experiment and apply different features to improve our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Attribue Name                Model    Acc False  True\n",
      "       number_of_downvotes_of_request_at_retrieval  Logistic Regression 0.7010 0.8129 0.2562\n",
      "                                                            Naive Bayes 0.7178 0.8276 0.2234\n",
      "                                                          Decision Tree 0.6842 0.7959 0.3020\n",
      "         number_of_upvotes_of_request_at_retrieval  Logistic Regression 0.7040 0.8146 0.2654\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6782 0.7907 0.3041\n",
      "                                   post_was_edited  Logistic Regression 0.7455 0.8542 0.0000\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6802 0.7931 0.2963\n",
      "           request_number_of_comments_at_retrieval  Logistic Regression 0.7099 0.8161 0.3138\n",
      "                                                            Naive Bayes 0.7198 0.8288 0.2289\n",
      "                                                          Decision Tree 0.7149 0.8132 0.3975\n",
      "          requester_account_age_in_days_at_request  Logistic Regression 0.7010 0.8122 0.2670\n",
      "                                                            Naive Bayes 0.7188 0.8283 0.2240\n",
      "                                                          Decision Tree 0.6663 0.7810 0.2994\n",
      "        requester_account_age_in_days_at_retrieval  Logistic Regression 0.6970 0.8095 0.2609\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6752 0.7908 0.2743\n",
      "requester_days_since_first_post_on_raop_at_request  Logistic Regression 0.7000 0.8112 0.2699\n",
      "                                                            Naive Bayes 0.7178 0.8276 0.2234\n",
      "                                                          Decision Tree 0.6535 0.7733 0.2647\n",
      "requester_days_since_first_post_on_raop_at_retriev  Logistic Regression 0.6871 0.8015 0.2617\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6584 0.7796 0.2418\n",
      "           requester_number_of_comments_at_request  Logistic Regression 0.6950 0.8087 0.2488\n",
      "                                                            Naive Bayes 0.7178 0.8276 0.2234\n",
      "                                                          Decision Tree 0.6644 0.7823 0.2678\n",
      "         requester_number_of_comments_at_retrieval  Logistic Regression 0.7010 0.8120 0.2705\n",
      "                                                            Naive Bayes 0.7198 0.8290 0.2247\n",
      "                                                          Decision Tree 0.6762 0.7897 0.2968\n",
      "   requester_number_of_comments_in_raop_at_request  Logistic Regression 0.7050 0.8154 0.2660\n",
      "                                                            Naive Bayes 0.7178 0.8276 0.2234\n",
      "                                                          Decision Tree 0.6851 0.7948 0.3234\n",
      " requester_number_of_comments_in_raop_at_retrieval  Logistic Regression 0.7208 0.8238 0.3286\n",
      "                                                            Naive Bayes 0.7218 0.8302 0.2301\n",
      "                                                          Decision Tree 0.7089 0.8073 0.4049\n",
      "              requester_number_of_posts_at_request  Logistic Regression 0.7050 0.8154 0.2660\n",
      "                                                            Naive Bayes 0.7178 0.8276 0.2234\n",
      "                                                          Decision Tree 0.6455 0.7690 0.2383\n",
      "            requester_number_of_posts_at_retrieval  Logistic Regression 0.7050 0.8154 0.2660\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6891 0.7972 0.3347\n",
      "      requester_number_of_posts_on_raop_at_request  Logistic Regression 0.7030 0.8130 0.2788\n",
      "                                                            Naive Bayes 0.7178 0.8276 0.2234\n",
      "                                                          Decision Tree 0.6594 0.7778 0.2712\n",
      "    requester_number_of_posts_on_raop_at_retrieval  Logistic Regression 0.7693 0.8534 0.4594\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.7703 0.8501 0.5085\n",
      "         requester_number_of_subreddits_at_request  Logistic Regression 0.6990 0.8116 0.2512\n",
      "                                                            Naive Bayes 0.7188 0.8283 0.2240\n",
      "                                                          Decision Tree 0.6634 0.7809 0.2735\n",
      "      requester_upvotes_minus_downvotes_at_request  Logistic Regression 0.6990 0.8107 0.2657\n",
      "                                                            Naive Bayes 0.7188 0.8283 0.2240\n",
      "                                                          Decision Tree 0.6594 0.7798 0.2489\n",
      "    requester_upvotes_minus_downvotes_at_retrieval  Logistic Regression 0.6950 0.8080 0.2596\n",
      "                                                            Naive Bayes 0.7198 0.8288 0.2289\n",
      "                                                          Decision Tree 0.6614 0.7791 0.2754\n",
      "       requester_upvotes_plus_downvotes_at_request  Logistic Regression 0.6990 0.8112 0.2585\n",
      "                                                            Naive Bayes 0.7188 0.8283 0.2240\n",
      "                                                          Decision Tree 0.6584 0.7793 0.2451\n",
      "     requester_upvotes_plus_downvotes_at_retrieval  Logistic Regression 0.7059 0.8159 0.2703\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6851 0.7967 0.3026\n",
      "                         unix_timestamp_of_request  Logistic Regression 0.7455 0.8542 0.0000\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6713 0.7872 0.2783\n",
      "                     unix_timestamp_of_request_utc  Logistic Regression 0.7455 0.8542 0.0000\n",
      "                                                            Naive Bayes 0.7188 0.8281 0.2283\n",
      "                                                          Decision Tree 0.6614 0.7788 0.2785\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "num_train_examples = train_data.shape[0]\n",
    "num_dev_examples = dev_data.shape[0]\n",
    "\n",
    "# We start with the preprocessed vocabulary as a basis\n",
    "# but we add a single field from the dataset\n",
    "def addFeature(field, tf_train, tf_dev):\n",
    "    new_train_col = train_data[field].values.reshape(num_train_examples,1)\n",
    "    new_dev_col = dev_data[field].values.reshape(num_dev_examples,1)\n",
    "    tf_train_plus = sp.sparse.hstack((tf_train, \n",
    "                                     new_train_col, \n",
    "                                     ), format='csr')\n",
    "    tf_dev_plus = sp.sparse.hstack((tf_dev, \n",
    "                                   new_dev_col, \n",
    "                                   ), format='csr')\n",
    "    return tf_train_plus, tf_dev_plus\n",
    "\n",
    "# print the table header\n",
    "print '%50.50s %20.20s %6.6s %5.5s %5.5s' %(\"Attribue Name\", \"Model\", \"Acc\", \"False\", \"True\")\n",
    "\n",
    "# Loop through all the different attribute fields in the dataset,\n",
    "# picking one out at a time to add to the feature vector to see how a single one improves (or not)\n",
    "for k in sorted(train_data.columns):\n",
    "    # skip these since we already have the text features\n",
    "    if (k == \"request_text\" or k == \"request_title\"):\n",
    "        continue\n",
    "    # these are giving the transform some compile errors, skipping them\n",
    "    elif (k == \"giver_username_if_known\" or\n",
    "          k == \"request_id\" or\n",
    "          k == \"request_text_edit_aware\" or\n",
    "          k == \"requester_subreddits_at_request\" or\n",
    "          k == \"requester_user_flair\" or\n",
    "          k == \"requester_username\"):\n",
    "        continue\n",
    "    # train basic models to gauge baseline performance of the models\n",
    "    # Logisitc Regression, Naive Bayes, Decision Tree\n",
    "    # calling af for added features\n",
    "    basic_af_lr = LogisticRegression()\n",
    "    basic_af_nb = BernoulliNB()\n",
    "    basic_af_dt = DecisionTreeClassifier()\n",
    "\n",
    "    # use this to flag if its the first model to print in the attribute\n",
    "    # used for formatting the print later\n",
    "    att_flag = 0\n",
    "    \n",
    "    tf_train_plus, tf_dev_plus = addFeature(k, tf_pp_train, tf_pp_dev)\n",
    "    \n",
    "    for model, model_name in [(basic_af_lr, 'Logistic Regression'), (basic_af_nb, 'Naive Bayes'),\n",
    "                      (basic_af_dt, 'Decision Tree')]:\n",
    "        accuracy, f1_score = train_and_evaluate_model(model, tf_train_plus, train_labels,\n",
    "                                                      tf_dev_plus, dev_labels)\n",
    "        #print_model_scores(model_name, accuracy, f1_score)\n",
    "        \n",
    "        # print a table of values\n",
    "        # attribute       model     accuracy f1_false f1_true\n",
    "        #                 model     accuracy f1_false f1_true\n",
    "        if (att_flag == 1):\n",
    "            print '%50.50s %20.20s %1.4f %1.4f %1.4f' %(\"\", model_name, accuracy, f1_score[0], f1_score[1])\n",
    "        else:\n",
    "            print '%50.50s %20.20s %1.4f %1.4f %1.4f' %(k, model_name, accuracy, f1_score[0], f1_score[1]) \n",
    "            att_flag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting findings here, the features: 'requester_number_of_comments_in_raop_at_retrieval' and 'requester_number_of_posts_on_raop_at_retrieval' seem to have a positive effect on prediction accuracy.  One possible reason is that the requester has continued to remain engaged in discussion with the community and people are more likely to help someone out who is engaged as opposed to users who request a pizza but are not heard from again, which may be interpreted by others as freeloading or begging.  Any engaged requester may be continuing to communicate their needs and are seen as part of the community.\n",
    "\n",
    "It's also interesting to see that the 'unix_timestamp_of_request' and 'unix_timestamp_of_request_utc' also have positive influence upon accuracy.  This appears to be the Unix time in epochs.  Adding this feature does not prove to explain or add to the story of overall accuracy, except perhaps, more recent requests are more or less likely to garner a pizza as the forum has gained or waned in popularity (most likely gained) and people are feeling more or less generous in that capacity.  For now, we will not be including that feature into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression model is 76.63%\n",
      "The F1 scores are: False: 84.99\n",
      "                    True: 47.32\n",
      "The accuracy of Naive Bayes model is 71.98%\n",
      "The F1 scores are: False: 82.88\n",
      "                    True: 22.89\n",
      "The accuracy of Decision Tree model is 79.5%\n",
      "The F1 scores are: False: 86.41\n",
      "                    True: 58.35\n"
     ]
    }
   ],
   "source": [
    "# introduce other features from the dataset to combine with text features we extracted\n",
    "# from the message bodies\n",
    "import scipy as sp\n",
    "\n",
    "num_train_examples = train_data.shape[0]\n",
    "num_dev_examples = dev_data.shape[0]\n",
    "\n",
    "# We start with the preprocessed vocabulary as a basis\n",
    "\n",
    "tf_train_plus = sp.sparse.hstack((\n",
    "                    tf_pp_train, \n",
    "                    train_data['number_of_upvotes_of_request_at_retrieval'].values.reshape(num_train_examples, 1), \n",
    "                    train_data['request_number_of_comments_at_retrieval'].values.reshape(num_train_examples, 1),\n",
    "                    train_data['requester_number_of_posts_on_raop_at_retrieval'].values.reshape(num_train_examples, 1),\n",
    "                    #train_data['unix_timestamp_of_request'].values.reshape(num_train_examples, 1),\n",
    "                ), format='csr')\n",
    "\n",
    "tf_dev_plus = sp.sparse.hstack((\n",
    "                    tf_pp_dev, \n",
    "                    dev_data['number_of_upvotes_of_request_at_retrieval'].values.reshape(num_dev_examples, 1), \n",
    "                    dev_data['request_number_of_comments_at_retrieval'].values.reshape(num_dev_examples, 1),\n",
    "                    dev_data['requester_number_of_posts_on_raop_at_retrieval'].values.reshape(num_dev_examples, 1),\n",
    "                    #dev_data['unix_timestamp_of_request'].values.reshape(num_dev_examples, 1),\n",
    "                ), format='csr')\n",
    "    \n",
    "# train basic models to gauge baseline performance of the models\n",
    "# Logisitc Regression\n",
    "# Naive Bayes\n",
    "# Decision Tree\n",
    "# calling af for added features\n",
    "basic_af_lr = LogisticRegression()\n",
    "basic_af_nb = BernoulliNB()\n",
    "basic_af_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({5: 'CV Vocab w AF'})\n",
    "accuracy_dict['CV Vocab w AF'] = {}\n",
    "for model, model_name in [(basic_af_lr, 'Logistic Regression'), (basic_af_nb, 'Naive Bayes'),\n",
    "                  (basic_af_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model, tf_train_plus, train_labels,\n",
    "                                                  tf_dev_plus, dev_labels)\n",
    "    accuracy_dict['CV Vocab w AF'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By introducing additional features from our dataset beyond the textual vocabulary, we were able to improve accuracy from our \"basic\" models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Reduction (L1 Regularization)\n",
    "\n",
    "We next attempt to improve the performance of our Logistic Regression model by first training such a model with L1 regularization and using only the features in that model that are non-zero as the input for a model that uses L2 regularization. We are effectively removing unimportant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11680 features have been removed, and 95 remain.\n",
      "The accuracy of Logistic Regression model is 73.27%\n",
      "The F1 scores are: False: 84.0\n",
      "                    True: 18.67\n",
      "The accuracy of Naive Bayes model is 68.91%\n",
      "The F1 scores are: False: 79.12\n",
      "                    True: 39.15\n",
      "The accuracy of Decision Tree model is 62.97%\n",
      "The F1 scores are: False: 74.76\n",
      "                    True: 30.48\n"
     ]
    }
   ],
   "source": [
    "# fit an L1 model \n",
    "lr_with_l1 = LogisticRegression(penalty='l1', C=.1, tol=.01)\n",
    "lr_with_l1.fit(tf_pp_train, train_labels)\n",
    "\n",
    "# find the features whose weights have not been reduced to 0\n",
    "non_zero_feature_indices = lr_with_l1.coef_.nonzero()[1]\n",
    "\n",
    "# use only those features as the input to the L2 model\n",
    "tf_train_reduced = tf_pp_train[:, non_zero_feature_indices]\n",
    "tf_dev_reduced = tf_pp_dev[:, non_zero_feature_indices]\n",
    "\n",
    "# see how many features we've eliminated\n",
    "features_remaining = tf_train_reduced.shape[1]\n",
    "\n",
    "print '{} features have been removed, and {} remain.'.format(\n",
    "    tf_train_plus.shape[1] - features_remaining, features_remaining) \n",
    "\n",
    "# score the revised model\n",
    "reduced_tf_lr = LogisticRegression()\n",
    "reduced_tf_nb = BernoulliNB()\n",
    "reduced_tf_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({6: 'L1 Reg Vocab'})\n",
    "accuracy_dict['L1 Reg Vocab'] = {}\n",
    "\n",
    "for model, model_name in [(reduced_tf_lr, 'Logistic Regression'), (reduced_tf_nb, 'Naive Bayes'),\n",
    "                  (reduced_tf_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model, tf_train_reduced, train_labels,\n",
    "                                                  tf_dev_reduced, dev_labels)\n",
    "    accuracy_dict['L1 Reg Vocab'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Things Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression model is 80.0%\n",
      "The F1 scores are: False: 86.2\n",
      "                    True: 63.67\n",
      "The accuracy of Naive Bayes model is 74.46%\n",
      "The F1 scores are: False: 85.36\n",
      "                    True: 0.0\n",
      "The accuracy of Decision Tree model is 81.39%\n",
      "The F1 scores are: False: 88.19\n",
      "                    True: 56.07\n"
     ]
    }
   ],
   "source": [
    "# Let's try combining some things for Logistic Regression\n",
    "# Using the uni-gram vocabulary plus additional features\n",
    "# We'll tune the model's C value (hyper parameter)\n",
    "# And apply weighting to see what kind of accuracy we can produce\n",
    "\n",
    "# start with L1 regularization to reduce our pre-processed vocabulary\n",
    "lr_with_l1 = LogisticRegression(penalty='l1', C=.1, tol=.01)\n",
    "lr_with_l1.fit(tfidf_pp_train, train_labels)\n",
    "\n",
    "# find the features whose weights have not been reduced to 0\n",
    "non_zero_feature_indices = lr_with_l1.coef_.nonzero()[1]\n",
    "\n",
    "# use only those features as the input to the L2 model\n",
    "tf_train_final = tfidf_pp_train[:, non_zero_feature_indices]\n",
    "tf_dev_final = tfidf_pp_dev[:, non_zero_feature_indices]\n",
    "\n",
    "# add additional features from the dataset\n",
    "tf_train_final = sp.sparse.hstack((\n",
    "                    tf_train_final, \n",
    "                    train_data['number_of_upvotes_of_request_at_retrieval'].values.reshape(num_train_examples, 1), \n",
    "                    train_data['request_number_of_comments_at_retrieval'].values.reshape(num_train_examples, 1),\n",
    "                    train_data['requester_number_of_posts_on_raop_at_retrieval'].values.reshape(num_train_examples, 1),\n",
    "                ), format='csr')\n",
    "\n",
    "tf_dev_final = sp.sparse.hstack((\n",
    "                    tf_dev_final,\n",
    "                    dev_data['number_of_upvotes_of_request_at_retrieval'].values.reshape(num_dev_examples, 1), \n",
    "                    dev_data['request_number_of_comments_at_retrieval'].values.reshape(num_dev_examples, 1),\n",
    "                    dev_data['requester_number_of_posts_on_raop_at_retrieval'].values.reshape(num_dev_examples, 1),\n",
    "                ), format='csr')\n",
    "\n",
    "# Generate the models\n",
    "final_lr = LogisticRegression(C=.25, class_weight='balanced')\n",
    "final_nb = BernoulliNB(alpha=10)\n",
    "final_dt = DecisionTreeClassifier()\n",
    "\n",
    "modification.update({7: 'Final'})\n",
    "accuracy_dict['Final'] = {}\n",
    "for model, model_name in [(final_lr, 'Logistic Regression'), (final_nb, 'Naive Bayes'),\n",
    "                  (final_dt, 'Decision Tree')]:\n",
    "    accuracy, f1_score = train_and_evaluate_model(model, tf_train_final, train_labels,\n",
    "                                                  tf_dev_final, dev_labels)\n",
    "    accuracy_dict['Final'].update({model_name: accuracy})\n",
    "    print_model_scores(model_name, accuracy, f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In our final modeling, we experimented with combining various aspects of modeling improvements.  We utilized TF-IDF (Term Frequency) vocabulary over the CV (Count Vectorized) vocabulary as in previous experiments it seemed to yield better overall accuracy.  We also applied the L1 reguarlization to reduce our vocabulary size by removing less frequently used words from our vocabulary.  Bi-Gram vocabularies did not yield significant improvments in our combined model, so they were ultimately left out for a uni-gram vocabulary.  We also introduced added features from our previous experiments which yielded improved accuracy along with accounting for class imbalance in our training set.\n",
    "\n",
    "By combing various improvments to the Logistic Regression model, we were able to predict with approximately 80% accuracy of our development dataset with good F1 scores.\n",
    "\n",
    "Naive Bayes under similar modeling conditions yielded slightly less accurate results at about 74%.  Worse off, the F1 score for the True class is 0, even with tuning.  We did see in previous modeling experiments, Naive Bayes did have low F1 scores with TF-IDF features as opposed to using CV.\n",
    "\n",
    "Decision Trees also proved quite reliable in accuracy at about 81% and also with decent F1 scores in both True and False categories.\n",
    "\n",
    "Below is a plot comparing our various modeling experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJIAAAF1CAYAAACzlMCCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHywbwUekwpusAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0fad69d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar graph of the different accuracies\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcdefaults()\n",
    "\n",
    "N = len(accuracy_dict)\n",
    "\n",
    "# build lists of scores for each model type\n",
    "nb_accuracy = []\n",
    "lr_accuracy = []\n",
    "dt_accuracy = []\n",
    "x_label_names = []\n",
    "for i in modification:\n",
    "    nb_accuracy.append(accuracy_dict[modification[i]]['Naive Bayes'])\n",
    "    lr_accuracy.append(accuracy_dict[modification[i]]['Logistic Regression'])\n",
    "    dt_accuracy.append(accuracy_dict[modification[i]]['Decision Tree'])\n",
    "    x_label_names.append(modification[i])\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.25        # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, lr_accuracy, width, color='r')\n",
    "rects2 = ax.bar(ind + width, nb_accuracy, width, color='g')\n",
    "rects3 = ax.bar(ind + width*2, dt_accuracy, width, color='b')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Model Accuracy')\n",
    "ax.set_title('Model Accuracy Comparision')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(x_label_names)\n",
    "\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Logistic Regression', 'Naive Bayes', 'Decision Tree'),\n",
    "         loc='lower right')\n",
    "\n",
    "# make the figure larger\n",
    "fig.set_size_inches(20,6)\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        h_text = str(\"%2.2f\" %(height*100))\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                h_text,\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "# change the y axis limit\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis((x1,x2,0,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giver_username_if_known</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>request_title</th>\n",
       "      <th>requester_account_age_in_days_at_request</th>\n",
       "      <th>requester_days_since_first_post_on_raop_at_request</th>\n",
       "      <th>requester_number_of_comments_at_request</th>\n",
       "      <th>requester_number_of_comments_in_raop_at_request</th>\n",
       "      <th>requester_number_of_posts_at_request</th>\n",
       "      <th>requester_number_of_posts_on_raop_at_request</th>\n",
       "      <th>requester_number_of_subreddits_at_request</th>\n",
       "      <th>requester_subreddits_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_request</th>\n",
       "      <th>requester_username</th>\n",
       "      <th>unix_timestamp_of_request</th>\n",
       "      <th>unix_timestamp_of_request_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_i8iy4</td>\n",
       "      <td>Hey all! It's about 95 degrees here and our ki...</td>\n",
       "      <td>[request] pregger gf 95 degree house and no fo...</td>\n",
       "      <td>42.083866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[AskReddit, COents, Denver, DenverBroncos, Lib...</td>\n",
       "      <td>364</td>\n",
       "      <td>840</td>\n",
       "      <td>j_like</td>\n",
       "      <td>1308963419</td>\n",
       "      <td>1308959819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1mfqi0</td>\n",
       "      <td>I didn't know a place like this exists! \\n\\nI ...</td>\n",
       "      <td>[Request] Lost my job day after labour day, st...</td>\n",
       "      <td>223.784537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[Android, AskReddit, GrandTheftAutoV, IAmA, Mi...</td>\n",
       "      <td>516</td>\n",
       "      <td>1448</td>\n",
       "      <td>0110110101101100</td>\n",
       "      <td>1379263523</td>\n",
       "      <td>1379259923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_lclka</td>\n",
       "      <td>Hi Reddit. Im a single dad having a really rou...</td>\n",
       "      <td>(Request) pizza for my kids please?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>singledad22601</td>\n",
       "      <td>1318636421</td>\n",
       "      <td>1318632821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1jdgdj</td>\n",
       "      <td>Hi I just moved to Waltham MA from my home sta...</td>\n",
       "      <td>[Request] Just moved to a new state(Waltham MA...</td>\n",
       "      <td>481.311273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>[AdviceAnimals, Art, AskReddit, GetMotivated, ...</td>\n",
       "      <td>1058</td>\n",
       "      <td>2062</td>\n",
       "      <td>Neuronut</td>\n",
       "      <td>1375220282</td>\n",
       "      <td>1375216682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_t2qt4</td>\n",
       "      <td>We're just sitting here near indianapolis on o...</td>\n",
       "      <td>[Request] Two girls in between paychecks, we'v...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>so_damn_hungry</td>\n",
       "      <td>1335934358</td>\n",
       "      <td>1335930758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_pvojb</td>\n",
       "      <td>So, I'm a student in London, and it's my birth...</td>\n",
       "      <td>[REQUEST] It's my birthday tomorrow (UK)</td>\n",
       "      <td>144.875093</td>\n",
       "      <td>44.114606</td>\n",
       "      <td>418</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>[Art, AskReddit, FIFA12, FantasyPL, IAmA, Life...</td>\n",
       "      <td>6331</td>\n",
       "      <td>31919</td>\n",
       "      <td>leiferic</td>\n",
       "      <td>1329601990</td>\n",
       "      <td>1329601990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_142n4c</td>\n",
       "      <td>I'm not entirely sure why, I guess just kindof...</td>\n",
       "      <td>[Request] Just kindof sad/disappointed, could ...</td>\n",
       "      <td>185.766100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Random_Acts_Of_Pizza, atheism, technology]</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>cafepressguy</td>\n",
       "      <td>1354312678</td>\n",
       "      <td>1354312678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_17rja6</td>\n",
       "      <td>I'm a visiting medical student from Costa Rica...</td>\n",
       "      <td>[Request] Visiting student could use warm food.</td>\n",
       "      <td>1198.620231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[AnimalPorn, AskReddit, Music, Random_Acts_Of_...</td>\n",
       "      <td>176</td>\n",
       "      <td>286</td>\n",
       "      <td>javilopez1</td>\n",
       "      <td>1359831611</td>\n",
       "      <td>1359831611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1lg6u2</td>\n",
       "      <td>My SO and I are moving to the new apartment to...</td>\n",
       "      <td>[Request] Pregnant, packing @ 2am to move tomo...</td>\n",
       "      <td>43.332118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[IAmA]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>RosyGraymalkin</td>\n",
       "      <td>1377933122</td>\n",
       "      <td>1377929522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1b0mtx</td>\n",
       "      <td>My partner is a wonderful gender-queer pansexu...</td>\n",
       "      <td>[Request] My partner and I hit six-months, we ...</td>\n",
       "      <td>787.698322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>[Anarchism, AnarchistNews, Anarcho_Capitalism,...</td>\n",
       "      <td>2796</td>\n",
       "      <td>5186</td>\n",
       "      <td>vomitisjustskimmilk</td>\n",
       "      <td>1364268605</td>\n",
       "      <td>1364265005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_mmivq</td>\n",
       "      <td>Apparently central heat is expensive, and I le...</td>\n",
       "      <td>[Request] Utilities nearly emptied my checking...</td>\n",
       "      <td>369.406910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>[Android, AskReddit, Boobies, Dredmor, EmmaWat...</td>\n",
       "      <td>2464</td>\n",
       "      <td>5494</td>\n",
       "      <td>txtsd</td>\n",
       "      <td>1322035223</td>\n",
       "      <td>1322035223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_11ux2a</td>\n",
       "      <td>I actually have money for the pizza but all I ...</td>\n",
       "      <td>[REQUEST] El Paso, TX. Out of food at home and...</td>\n",
       "      <td>46.500949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[AskReddit, Music, WTF, aww, deftones, funny]</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>DrunkenPopTart</td>\n",
       "      <td>1350854274</td>\n",
       "      <td>1350850674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_klige</td>\n",
       "      <td>Okay, so I'm not exactly in the worst place se...</td>\n",
       "      <td>(Request) Broke and unemployed writer in OR</td>\n",
       "      <td>116.439965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[AdviceAnimals, Gunsforsale, answers, bestoftr...</td>\n",
       "      <td>193</td>\n",
       "      <td>397</td>\n",
       "      <td>Java980</td>\n",
       "      <td>1316524577</td>\n",
       "      <td>1316520977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>harrisonfire</td>\n",
       "      <td>t3_1iv3cj</td>\n",
       "      <td>Hey guys, so as the title implies I'm a colleg...</td>\n",
       "      <td>[Request] Broke FSU student hoping for some pizza</td>\n",
       "      <td>460.134225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[NoFap, ValhallaChallenge, WTF, asmr, baseball...</td>\n",
       "      <td>582</td>\n",
       "      <td>740</td>\n",
       "      <td>darthfapper</td>\n",
       "      <td>1374556106</td>\n",
       "      <td>1374552506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_13dh0w</td>\n",
       "      <td>I am in Lubbock TX.  Anyone willing to help a ...</td>\n",
       "      <td>{request}  Stuck at work until midnight, left ...</td>\n",
       "      <td>137.466736</td>\n",
       "      <td>6.011111</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>[AskReddit, BobNewhart, FreeKarma, Hawkman, Lu...</td>\n",
       "      <td>1265</td>\n",
       "      <td>2095</td>\n",
       "      <td>stegogo</td>\n",
       "      <td>1353195597</td>\n",
       "      <td>1353195597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_li326</td>\n",
       "      <td>Hey y'all.\\n\\nSo, I live in Fort Worth TX. I'm...</td>\n",
       "      <td>[REQUEST] Broke and frazzled college student, ...</td>\n",
       "      <td>25.751748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[AskReddit, IAmA, Music, PostHardcore, Sinfoni...</td>\n",
       "      <td>96</td>\n",
       "      <td>142</td>\n",
       "      <td>ASD_Sinfonian</td>\n",
       "      <td>1319072110</td>\n",
       "      <td>1319068510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_xww8y</td>\n",
       "      <td>My sister told me about this, last week the wi...</td>\n",
       "      <td>[REQUEST] My wife left the kids and I.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Littleworldbigheart</td>\n",
       "      <td>1344477471</td>\n",
       "      <td>1344473871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_kogen</td>\n",
       "      <td>I hate asking for help from people but we real...</td>\n",
       "      <td>[Request] Me, my girlfriend and my roomates us...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fudging_starving</td>\n",
       "      <td>1316737639</td>\n",
       "      <td>1316734039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_ik8w1</td>\n",
       "      <td>Is anyone willing to help me out while I make ...</td>\n",
       "      <td>[REQUEST] New place, no kitchen. Los Angeles, CA</td>\n",
       "      <td>116.057986</td>\n",
       "      <td>9.813275</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>[AskReddit, CityOfLA, DoesAnybodyElse, IAmA, L...</td>\n",
       "      <td>2650</td>\n",
       "      <td>14450</td>\n",
       "      <td>Trioxin</td>\n",
       "      <td>1310154205</td>\n",
       "      <td>1310150605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_j3nnl</td>\n",
       "      <td>I've got a guitar in one hand and the other is...</td>\n",
       "      <td>[REQUEST] TX. Just a guy with a guitar tryin t...</td>\n",
       "      <td>32.599560</td>\n",
       "      <td>0.799583</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[AskReddit, IAmA, Random_Acts_Of_Pizza, circle...</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>leftyguitarguy</td>\n",
       "      <td>1311982380</td>\n",
       "      <td>1311978780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_j6xvd</td>\n",
       "      <td>Woke up with a massive headache and sore throa...</td>\n",
       "      <td>[REQUEST] Felt like crap today, had some bad l...</td>\n",
       "      <td>131.801319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[gaming, leagueoflegends]</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>lolcatcatlol</td>\n",
       "      <td>1312314486</td>\n",
       "      <td>1312310886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1lsrj5</td>\n",
       "      <td>Been a bad week, My birthday was followed by m...</td>\n",
       "      <td>[Request] Just need a picker uper in Colorado ...</td>\n",
       "      <td>129.968160</td>\n",
       "      <td>75.894201</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[Random_Acts_Of_Amazon, Random_Acts_Of_Pizza, ...</td>\n",
       "      <td>1671</td>\n",
       "      <td>1941</td>\n",
       "      <td>wildcatz311</td>\n",
       "      <td>1378408533</td>\n",
       "      <td>1378404933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_idld7</td>\n",
       "      <td>Its kinda hard to ask....I and my wife and 3 k...</td>\n",
       "      <td>[REQUEST] Family Needs Help</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wolfknight</td>\n",
       "      <td>1309470238</td>\n",
       "      <td>1309466638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_y6amf</td>\n",
       "      <td>None of the big 3 deliver here...  sorry.  I'm...</td>\n",
       "      <td>[Request]  I'm hungry.</td>\n",
       "      <td>486.915231</td>\n",
       "      <td>178.024005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>[AdviceAnimals, ArcherFX, AskReddit, Boxing, D...</td>\n",
       "      <td>1895</td>\n",
       "      <td>9405</td>\n",
       "      <td>sterling_mallory</td>\n",
       "      <td>1344907515</td>\n",
       "      <td>1344903915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_hl0ft</td>\n",
       "      <td>My dad has helped me out of so many binds that...</td>\n",
       "      <td>[REQUEST] I don't want to ask for my dad's hel...</td>\n",
       "      <td>364.348611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>[AdviceAnimals, AskReddit, Bass, Dogfort, Frug...</td>\n",
       "      <td>1927</td>\n",
       "      <td>8773</td>\n",
       "      <td>flinteastwood</td>\n",
       "      <td>1306451174</td>\n",
       "      <td>1306447574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_jg6yk</td>\n",
       "      <td>I am here asking for a Pizza dinner for my fam...</td>\n",
       "      <td>\\n[REQUEST] Small family would love a Pizza Di...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sweetpeamommy</td>\n",
       "      <td>1313107673</td>\n",
       "      <td>1313104073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1k5ss6</td>\n",
       "      <td>So... long story short, I'm crashing at my mot...</td>\n",
       "      <td>[Request] God damnit Mom.</td>\n",
       "      <td>542.437396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>[AdviceAnimals, AmateurArchives, AsianHotties,...</td>\n",
       "      <td>2326</td>\n",
       "      <td>4402</td>\n",
       "      <td>deimosian</td>\n",
       "      <td>1376254795</td>\n",
       "      <td>1376251195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_u6i4z</td>\n",
       "      <td>My husband, 10 month old son and I are in the ...</td>\n",
       "      <td>[Request] Louisiana, USA - Moving; packed up e...</td>\n",
       "      <td>26.321782</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[LadyBoners, MakeupAddiction, Random_Acts_Of_P...</td>\n",
       "      <td>533</td>\n",
       "      <td>651</td>\n",
       "      <td>plaidsuitpants</td>\n",
       "      <td>1338074026</td>\n",
       "      <td>1338070426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_ltuhq</td>\n",
       "      <td>There isn't anything to eat in my house, and I...</td>\n",
       "      <td>[REQUEST] Hungry and would appreciate some pizza</td>\n",
       "      <td>90.358218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[AskReddit, deadisland, gaming, hockey, loseit...</td>\n",
       "      <td>34</td>\n",
       "      <td>176</td>\n",
       "      <td>Oosterhuis</td>\n",
       "      <td>1319953020</td>\n",
       "      <td>1319949420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1m2om7</td>\n",
       "      <td>Me and my brother are without food tonight. We...</td>\n",
       "      <td>[Request] anyone wanna help us out?</td>\n",
       "      <td>487.886019</td>\n",
       "      <td>321.217477</td>\n",
       "      <td>956</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>[AskReddit, Dexter, DoesAnybodyElse, IAmA, Let...</td>\n",
       "      <td>11465</td>\n",
       "      <td>23643</td>\n",
       "      <td>Totesmcgotes702</td>\n",
       "      <td>1378779268</td>\n",
       "      <td>1378775668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_smcni</td>\n",
       "      <td>I'm running out of money, so is my girlfriend,...</td>\n",
       "      <td>[Request] College student hoping to get pizza ...</td>\n",
       "      <td>156.941539</td>\n",
       "      <td>138.401910</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[AskReddit, AtheismComingOut, BoyScouts, Color...</td>\n",
       "      <td>698</td>\n",
       "      <td>1580</td>\n",
       "      <td>dicastio</td>\n",
       "      <td>1335078942</td>\n",
       "      <td>1335075342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_zzsho</td>\n",
       "      <td>I packed up my entire apartment today and only...</td>\n",
       "      <td>Request-south Florida USA-moving back to Maryl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lucy_dog</td>\n",
       "      <td>1347841196</td>\n",
       "      <td>1347837596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_pr3p3</td>\n",
       "      <td>I thought for a while to post up something abo...</td>\n",
       "      <td>[REQUEST] Ireland, Got a serious craving right...</td>\n",
       "      <td>169.143218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[DrunkTank, Guitar, Random_Acts_Of_Pizza, blue...</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>PeterMacIrish</td>\n",
       "      <td>1329334612</td>\n",
       "      <td>1329334612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1hluyc</td>\n",
       "      <td></td>\n",
       "      <td>[Request, WA] It's my saturday, but two days a...</td>\n",
       "      <td>314.789907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>[AdviceAnimals, AskReddit, IAmA, Music, WTF, W...</td>\n",
       "      <td>665</td>\n",
       "      <td>1115</td>\n",
       "      <td>numberthirteen</td>\n",
       "      <td>1372905658</td>\n",
       "      <td>1372902058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_k025c</td>\n",
       "      <td>[EDIT] I live in Mesa, AZ 85201 &amp;lt;- thanks t...</td>\n",
       "      <td>[REQUEST] Student - job went through the crapper</td>\n",
       "      <td>116.724583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[AdviceAnimals, Android, GoneWildPlus, IAmA, a...</td>\n",
       "      <td>637</td>\n",
       "      <td>3345</td>\n",
       "      <td>williambueti</td>\n",
       "      <td>1314790432</td>\n",
       "      <td>1314786832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1go8c1</td>\n",
       "      <td>This is kind of embarrassing for me...\\nI can ...</td>\n",
       "      <td>[Request]Spokane, WA I only get paid once a mo...</td>\n",
       "      <td>125.638819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[AdviceAnimals, AskReddit, IAmA, MakeupAddicti...</td>\n",
       "      <td>1773</td>\n",
       "      <td>3171</td>\n",
       "      <td>FlaxwenchPromise</td>\n",
       "      <td>1371671770</td>\n",
       "      <td>1371668170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>thumpingarnt</td>\n",
       "      <td>t3_ihhbr</td>\n",
       "      <td>Before I start, allow me to say that I do real...</td>\n",
       "      <td>[Request] Hoping for some pizza for myself and...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YepImBroke</td>\n",
       "      <td>1309901494</td>\n",
       "      <td>1309897894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1ckfzz</td>\n",
       "      <td>With Boston and all I'm pretty much on the bot...</td>\n",
       "      <td>[Request]I'm pretty hungry and have a few days...</td>\n",
       "      <td>1912.394873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>992</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>[4chan, AdviceAnimals, Android, AskReddit, Bac...</td>\n",
       "      <td>4580</td>\n",
       "      <td>7500</td>\n",
       "      <td>Xeiliex</td>\n",
       "      <td>1366243905</td>\n",
       "      <td>1366240305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1l7ksf</td>\n",
       "      <td>All of our small money went to textbooks and r...</td>\n",
       "      <td>[REQUEST] Poor, LA college students with no mo...</td>\n",
       "      <td>369.507315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[AskReddit, Baking, FilmIndustryLA, LearnJapan...</td>\n",
       "      <td>183</td>\n",
       "      <td>269</td>\n",
       "      <td>etiolates</td>\n",
       "      <td>1377637800</td>\n",
       "      <td>1377634200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_vawcb</td>\n",
       "      <td>I am currently in the process of a move and ha...</td>\n",
       "      <td>[Request] Broke, Moving, Need Energy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ShludleDoodle</td>\n",
       "      <td>1340154613</td>\n",
       "      <td>1340151013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_mody8</td>\n",
       "      <td>So I'm a broke college student (big surprise!)...</td>\n",
       "      <td>[Request] Broke college student spending Thank...</td>\n",
       "      <td>334.641759</td>\n",
       "      <td>22.776782</td>\n",
       "      <td>562</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>[Advice, AdviceAnimals, AmISexy, AskReddit, Bo...</td>\n",
       "      <td>5205</td>\n",
       "      <td>12951</td>\n",
       "      <td>bananaslughippie</td>\n",
       "      <td>1322181527</td>\n",
       "      <td>1322181527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1foy3z</td>\n",
       "      <td>I've been working since 5 without a meal since...</td>\n",
       "      <td>[Request] Durham NH broke call center employee...</td>\n",
       "      <td>515.844769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[BostonBruins, IAmA, aww, hockey, nhl, trees]</td>\n",
       "      <td>2367</td>\n",
       "      <td>3327</td>\n",
       "      <td>FlyingCouch</td>\n",
       "      <td>1370399740</td>\n",
       "      <td>1370396140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_qzu4g</td>\n",
       "      <td>http://oi42.tinypic.com/1ht284.jpg\\nHungry! Th...</td>\n",
       "      <td>[REQUEST]Blah... in NS, Canada</td>\n",
       "      <td>37.674549</td>\n",
       "      <td>35.733275</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[AskSocialScience, RandomActsOfCookies, Random...</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>Krissp</td>\n",
       "      <td>1331931696</td>\n",
       "      <td>1331928096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_lmb89</td>\n",
       "      <td>My boyfriend, roommate, and I moved into an ap...</td>\n",
       "      <td>[Request] Being kicked out on Halloween and ha...</td>\n",
       "      <td>84.409167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[Android, AskReddit, Dreams, funny, ihaveissue...</td>\n",
       "      <td>101</td>\n",
       "      <td>331</td>\n",
       "      <td>AwesomeIncarnate</td>\n",
       "      <td>1319404428</td>\n",
       "      <td>1319400828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1m53fu</td>\n",
       "      <td>This is a final option for me as far as gettin...</td>\n",
       "      <td>[Request] Roommate just left me high and dry. ...</td>\n",
       "      <td>558.961759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>[AskReddit, Blink182, Diablo, FinalFantasy, Gu...</td>\n",
       "      <td>410</td>\n",
       "      <td>710</td>\n",
       "      <td>HayleyWearsPrada</td>\n",
       "      <td>1378861954</td>\n",
       "      <td>1378858354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_10cy64</td>\n",
       "      <td>As we all well know, borderlands 2 just came o...</td>\n",
       "      <td>[Request] borderlands two ate my money</td>\n",
       "      <td>3.952766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[AskReddit, Borderlands, Borderlands2, IAmA, M...</td>\n",
       "      <td>329</td>\n",
       "      <td>449</td>\n",
       "      <td>Kincade117</td>\n",
       "      <td>1348439756</td>\n",
       "      <td>1348436156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>in2itiveact</td>\n",
       "      <td>t3_m7m7l</td>\n",
       "      <td>I've been wanting a pizza for a while but all ...</td>\n",
       "      <td>[Request][US] Not enough money for pizza</td>\n",
       "      <td>154.612060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Random_Acts_Of_Pizza, starcraft]</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Kappn</td>\n",
       "      <td>1320946591</td>\n",
       "      <td>1320946591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1lfrlc</td>\n",
       "      <td>Worked in a cabinet shop, no work, laid off, n...</td>\n",
       "      <td>[ReQuest] Lost my job, moved in with parents, ...</td>\n",
       "      <td>156.692593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[AdviceAnimals, AskReddit, IAmA, SquaredCircle...</td>\n",
       "      <td>210</td>\n",
       "      <td>466</td>\n",
       "      <td>Foley_is_Good</td>\n",
       "      <td>1377915885</td>\n",
       "      <td>1377912285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_iihye</td>\n",
       "      <td>Hey everyone, i was referred to this site by a...</td>\n",
       "      <td>requesting some pizza for tonight!!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>msmunn87</td>\n",
       "      <td>1309995182</td>\n",
       "      <td>1309991582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_xn5hp</td>\n",
       "      <td>27 year old Air Force guy with a wife and 5 mo...</td>\n",
       "      <td>[request] Las Vegas military dude, would love ...</td>\n",
       "      <td>415.173854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>[AdviceAnimals, AirForce, AskReddit, Fitness, ...</td>\n",
       "      <td>6065</td>\n",
       "      <td>56809</td>\n",
       "      <td>chinchilla618</td>\n",
       "      <td>1344035842</td>\n",
       "      <td>1344032242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_ro9ud</td>\n",
       "      <td>We are both redditors looking for some goodnes...</td>\n",
       "      <td>(Request) two buddies working on a Sunday wond...</td>\n",
       "      <td>470.938970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[AskReddit, Denver, Economics, WTF, boulder, d...</td>\n",
       "      <td>844</td>\n",
       "      <td>2356</td>\n",
       "      <td>Colorado222</td>\n",
       "      <td>1333309151</td>\n",
       "      <td>1333305551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_kx1pn</td>\n",
       "      <td>My girlfriend and I are going through some rea...</td>\n",
       "      <td>[request]Times are really hard right now, and ...</td>\n",
       "      <td>58.021331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[ArtHistory, AskElectronics, AskReddit, Minecr...</td>\n",
       "      <td>946</td>\n",
       "      <td>7158</td>\n",
       "      <td>withoutamartyr</td>\n",
       "      <td>1317432554</td>\n",
       "      <td>1317428954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1cn0h3</td>\n",
       "      <td>Let me tell you about the coolest fuckin' rat ...</td>\n",
       "      <td>[request] My pet rat, Cheesy died today. He go...</td>\n",
       "      <td>61.246644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[offmychest, trees]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>KindOfWatchingYou</td>\n",
       "      <td>1366328655</td>\n",
       "      <td>1366325055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_zq12j</td>\n",
       "      <td>Hey everyone...I would be so honored if someon...</td>\n",
       "      <td>[Request]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>theniceiceman</td>\n",
       "      <td>1347393775</td>\n",
       "      <td>1347390175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_1br2hm</td>\n",
       "      <td>Had my phone stolen off me twice in two months...</td>\n",
       "      <td>[Request] [UK]Two crimes in two months and som...</td>\n",
       "      <td>182.852870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[LondonSocialClub, androiddev, cpp, java, lond...</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>SomniSmith</td>\n",
       "      <td>1365192686</td>\n",
       "      <td>1365189086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_knttk</td>\n",
       "      <td>About two months ago, myself and three friends...</td>\n",
       "      <td>[Request] Guy in the Cabin</td>\n",
       "      <td>240.632060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[AskReddit, Austria, IAmA, gameofthrones, game...</td>\n",
       "      <td>687</td>\n",
       "      <td>2079</td>\n",
       "      <td>post91</td>\n",
       "      <td>1316697470</td>\n",
       "      <td>1316693870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>crakhed</td>\n",
       "      <td>t3_11wza2</td>\n",
       "      <td>I just spent $75 dollars paying to get my appl...</td>\n",
       "      <td>[Request] California USA  Last of my money wen...</td>\n",
       "      <td>49.641481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[AskReddit, AskWomen, IAmA, LetsNotMeet, Modes...</td>\n",
       "      <td>2094</td>\n",
       "      <td>2876</td>\n",
       "      <td>AccioNeedles</td>\n",
       "      <td>1350957149</td>\n",
       "      <td>1350953549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_iwbsf</td>\n",
       "      <td>I live in Monterrey Mexico, yup the city of Na...</td>\n",
       "      <td>[Request] MONTERREY, I'm hungry :( I hope we M...</td>\n",
       "      <td>105.348530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>[AskReddit, IAmA, Monterrey, ads, beermoney, b...</td>\n",
       "      <td>1109</td>\n",
       "      <td>6689</td>\n",
       "      <td>ivanbco</td>\n",
       "      <td>1311296237</td>\n",
       "      <td>1311292637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_nys7g</td>\n",
       "      <td>I am 23, have been in the service industry for...</td>\n",
       "      <td>[REQUEST] A bit hungover, broke (even though I...</td>\n",
       "      <td>20.693403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[AskReddit, Austin, DoesAnybodyElse, IAmA, Ran...</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>table95</td>\n",
       "      <td>1325444789</td>\n",
       "      <td>1325444789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_17pmtu</td>\n",
       "      <td>We could just really go for some pizza right n...</td>\n",
       "      <td>[Request] Nothing sad here, just a couple of h...</td>\n",
       "      <td>81.649005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[DoesAnybodyElse, IAmA, LadyBoners, Random_Act...</td>\n",
       "      <td>79</td>\n",
       "      <td>123</td>\n",
       "      <td>Clurshank</td>\n",
       "      <td>1359748168</td>\n",
       "      <td>1359748168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     giver_username_if_known request_id  \\\n",
       "0                        N/A   t3_i8iy4   \n",
       "1                        N/A  t3_1mfqi0   \n",
       "2                        N/A   t3_lclka   \n",
       "3                        N/A  t3_1jdgdj   \n",
       "4                        N/A   t3_t2qt4   \n",
       "5                        N/A   t3_pvojb   \n",
       "6                        N/A  t3_142n4c   \n",
       "7                        N/A  t3_17rja6   \n",
       "8                        N/A  t3_1lg6u2   \n",
       "9                        N/A  t3_1b0mtx   \n",
       "10                       N/A   t3_mmivq   \n",
       "11                       N/A  t3_11ux2a   \n",
       "12                       N/A   t3_klige   \n",
       "13              harrisonfire  t3_1iv3cj   \n",
       "14                       N/A  t3_13dh0w   \n",
       "15                       N/A   t3_li326   \n",
       "16                       N/A   t3_xww8y   \n",
       "17                       N/A   t3_kogen   \n",
       "18                       N/A   t3_ik8w1   \n",
       "19                       N/A   t3_j3nnl   \n",
       "20                       N/A   t3_j6xvd   \n",
       "21                       N/A  t3_1lsrj5   \n",
       "22                       N/A   t3_idld7   \n",
       "23                       N/A   t3_y6amf   \n",
       "24                       N/A   t3_hl0ft   \n",
       "25                       N/A   t3_jg6yk   \n",
       "26                       N/A  t3_1k5ss6   \n",
       "27                       N/A   t3_u6i4z   \n",
       "28                       N/A   t3_ltuhq   \n",
       "29                       N/A  t3_1m2om7   \n",
       "...                      ...        ...   \n",
       "1601                     N/A   t3_smcni   \n",
       "1602                     N/A   t3_zzsho   \n",
       "1603                     N/A   t3_pr3p3   \n",
       "1604                     N/A  t3_1hluyc   \n",
       "1605                     N/A   t3_k025c   \n",
       "1606                     N/A  t3_1go8c1   \n",
       "1607            thumpingarnt   t3_ihhbr   \n",
       "1608                     N/A  t3_1ckfzz   \n",
       "1609                     N/A  t3_1l7ksf   \n",
       "1610                     N/A   t3_vawcb   \n",
       "1611                     N/A   t3_mody8   \n",
       "1612                     N/A  t3_1foy3z   \n",
       "1613                     N/A   t3_qzu4g   \n",
       "1614                     N/A   t3_lmb89   \n",
       "1615                     N/A  t3_1m53fu   \n",
       "1616                     N/A  t3_10cy64   \n",
       "1617             in2itiveact   t3_m7m7l   \n",
       "1618                     N/A  t3_1lfrlc   \n",
       "1619                     N/A   t3_iihye   \n",
       "1620                     N/A   t3_xn5hp   \n",
       "1621                     N/A   t3_ro9ud   \n",
       "1622                     N/A   t3_kx1pn   \n",
       "1623                     N/A  t3_1cn0h3   \n",
       "1624                     N/A   t3_zq12j   \n",
       "1625                     N/A  t3_1br2hm   \n",
       "1626                     N/A   t3_knttk   \n",
       "1627                 crakhed  t3_11wza2   \n",
       "1628                     N/A   t3_iwbsf   \n",
       "1629                     N/A   t3_nys7g   \n",
       "1630                     N/A  t3_17pmtu   \n",
       "\n",
       "                                request_text_edit_aware  \\\n",
       "0     Hey all! It's about 95 degrees here and our ki...   \n",
       "1     I didn't know a place like this exists! \\n\\nI ...   \n",
       "2     Hi Reddit. Im a single dad having a really rou...   \n",
       "3     Hi I just moved to Waltham MA from my home sta...   \n",
       "4     We're just sitting here near indianapolis on o...   \n",
       "5     So, I'm a student in London, and it's my birth...   \n",
       "6     I'm not entirely sure why, I guess just kindof...   \n",
       "7     I'm a visiting medical student from Costa Rica...   \n",
       "8     My SO and I are moving to the new apartment to...   \n",
       "9     My partner is a wonderful gender-queer pansexu...   \n",
       "10    Apparently central heat is expensive, and I le...   \n",
       "11    I actually have money for the pizza but all I ...   \n",
       "12    Okay, so I'm not exactly in the worst place se...   \n",
       "13    Hey guys, so as the title implies I'm a colleg...   \n",
       "14    I am in Lubbock TX.  Anyone willing to help a ...   \n",
       "15    Hey y'all.\\n\\nSo, I live in Fort Worth TX. I'm...   \n",
       "16    My sister told me about this, last week the wi...   \n",
       "17    I hate asking for help from people but we real...   \n",
       "18    Is anyone willing to help me out while I make ...   \n",
       "19    I've got a guitar in one hand and the other is...   \n",
       "20    Woke up with a massive headache and sore throa...   \n",
       "21    Been a bad week, My birthday was followed by m...   \n",
       "22    Its kinda hard to ask....I and my wife and 3 k...   \n",
       "23    None of the big 3 deliver here...  sorry.  I'm...   \n",
       "24    My dad has helped me out of so many binds that...   \n",
       "25    I am here asking for a Pizza dinner for my fam...   \n",
       "26    So... long story short, I'm crashing at my mot...   \n",
       "27    My husband, 10 month old son and I are in the ...   \n",
       "28    There isn't anything to eat in my house, and I...   \n",
       "29    Me and my brother are without food tonight. We...   \n",
       "...                                                 ...   \n",
       "1601  I'm running out of money, so is my girlfriend,...   \n",
       "1602  I packed up my entire apartment today and only...   \n",
       "1603  I thought for a while to post up something abo...   \n",
       "1604                                                      \n",
       "1605  [EDIT] I live in Mesa, AZ 85201 &lt;- thanks t...   \n",
       "1606  This is kind of embarrassing for me...\\nI can ...   \n",
       "1607  Before I start, allow me to say that I do real...   \n",
       "1608  With Boston and all I'm pretty much on the bot...   \n",
       "1609  All of our small money went to textbooks and r...   \n",
       "1610  I am currently in the process of a move and ha...   \n",
       "1611  So I'm a broke college student (big surprise!)...   \n",
       "1612  I've been working since 5 without a meal since...   \n",
       "1613  http://oi42.tinypic.com/1ht284.jpg\\nHungry! Th...   \n",
       "1614  My boyfriend, roommate, and I moved into an ap...   \n",
       "1615  This is a final option for me as far as gettin...   \n",
       "1616  As we all well know, borderlands 2 just came o...   \n",
       "1617  I've been wanting a pizza for a while but all ...   \n",
       "1618  Worked in a cabinet shop, no work, laid off, n...   \n",
       "1619  Hey everyone, i was referred to this site by a...   \n",
       "1620  27 year old Air Force guy with a wife and 5 mo...   \n",
       "1621  We are both redditors looking for some goodnes...   \n",
       "1622  My girlfriend and I are going through some rea...   \n",
       "1623  Let me tell you about the coolest fuckin' rat ...   \n",
       "1624  Hey everyone...I would be so honored if someon...   \n",
       "1625  Had my phone stolen off me twice in two months...   \n",
       "1626  About two months ago, myself and three friends...   \n",
       "1627  I just spent $75 dollars paying to get my appl...   \n",
       "1628  I live in Monterrey Mexico, yup the city of Na...   \n",
       "1629  I am 23, have been in the service industry for...   \n",
       "1630  We could just really go for some pizza right n...   \n",
       "\n",
       "                                          request_title  \\\n",
       "0     [request] pregger gf 95 degree house and no fo...   \n",
       "1     [Request] Lost my job day after labour day, st...   \n",
       "2                   (Request) pizza for my kids please?   \n",
       "3     [Request] Just moved to a new state(Waltham MA...   \n",
       "4     [Request] Two girls in between paychecks, we'v...   \n",
       "5              [REQUEST] It's my birthday tomorrow (UK)   \n",
       "6     [Request] Just kindof sad/disappointed, could ...   \n",
       "7       [Request] Visiting student could use warm food.   \n",
       "8     [Request] Pregnant, packing @ 2am to move tomo...   \n",
       "9     [Request] My partner and I hit six-months, we ...   \n",
       "10    [Request] Utilities nearly emptied my checking...   \n",
       "11    [REQUEST] El Paso, TX. Out of food at home and...   \n",
       "12          (Request) Broke and unemployed writer in OR   \n",
       "13    [Request] Broke FSU student hoping for some pizza   \n",
       "14    {request}  Stuck at work until midnight, left ...   \n",
       "15    [REQUEST] Broke and frazzled college student, ...   \n",
       "16               [REQUEST] My wife left the kids and I.   \n",
       "17    [Request] Me, my girlfriend and my roomates us...   \n",
       "18     [REQUEST] New place, no kitchen. Los Angeles, CA   \n",
       "19    [REQUEST] TX. Just a guy with a guitar tryin t...   \n",
       "20    [REQUEST] Felt like crap today, had some bad l...   \n",
       "21    [Request] Just need a picker uper in Colorado ...   \n",
       "22                          [REQUEST] Family Needs Help   \n",
       "23                               [Request]  I'm hungry.   \n",
       "24    [REQUEST] I don't want to ask for my dad's hel...   \n",
       "25    \\n[REQUEST] Small family would love a Pizza Di...   \n",
       "26                            [Request] God damnit Mom.   \n",
       "27    [Request] Louisiana, USA - Moving; packed up e...   \n",
       "28     [REQUEST] Hungry and would appreciate some pizza   \n",
       "29                  [Request] anyone wanna help us out?   \n",
       "...                                                 ...   \n",
       "1601  [Request] College student hoping to get pizza ...   \n",
       "1602  Request-south Florida USA-moving back to Maryl...   \n",
       "1603  [REQUEST] Ireland, Got a serious craving right...   \n",
       "1604  [Request, WA] It's my saturday, but two days a...   \n",
       "1605   [REQUEST] Student - job went through the crapper   \n",
       "1606  [Request]Spokane, WA I only get paid once a mo...   \n",
       "1607  [Request] Hoping for some pizza for myself and...   \n",
       "1608  [Request]I'm pretty hungry and have a few days...   \n",
       "1609  [REQUEST] Poor, LA college students with no mo...   \n",
       "1610               [Request] Broke, Moving, Need Energy   \n",
       "1611  [Request] Broke college student spending Thank...   \n",
       "1612  [Request] Durham NH broke call center employee...   \n",
       "1613                     [REQUEST]Blah... in NS, Canada   \n",
       "1614  [Request] Being kicked out on Halloween and ha...   \n",
       "1615  [Request] Roommate just left me high and dry. ...   \n",
       "1616             [Request] borderlands two ate my money   \n",
       "1617           [Request][US] Not enough money for pizza   \n",
       "1618  [ReQuest] Lost my job, moved in with parents, ...   \n",
       "1619                requesting some pizza for tonight!!   \n",
       "1620  [request] Las Vegas military dude, would love ...   \n",
       "1621  (Request) two buddies working on a Sunday wond...   \n",
       "1622  [request]Times are really hard right now, and ...   \n",
       "1623  [request] My pet rat, Cheesy died today. He go...   \n",
       "1624                                          [Request]   \n",
       "1625  [Request] [UK]Two crimes in two months and som...   \n",
       "1626                         [Request] Guy in the Cabin   \n",
       "1627  [Request] California USA  Last of my money wen...   \n",
       "1628  [Request] MONTERREY, I'm hungry :( I hope we M...   \n",
       "1629  [REQUEST] A bit hungover, broke (even though I...   \n",
       "1630  [Request] Nothing sad here, just a couple of h...   \n",
       "\n",
       "      requester_account_age_in_days_at_request  \\\n",
       "0                                    42.083866   \n",
       "1                                   223.784537   \n",
       "2                                     0.000000   \n",
       "3                                   481.311273   \n",
       "4                                     0.000000   \n",
       "5                                   144.875093   \n",
       "6                                   185.766100   \n",
       "7                                  1198.620231   \n",
       "8                                    43.332118   \n",
       "9                                   787.698322   \n",
       "10                                  369.406910   \n",
       "11                                   46.500949   \n",
       "12                                  116.439965   \n",
       "13                                  460.134225   \n",
       "14                                  137.466736   \n",
       "15                                   25.751748   \n",
       "16                                    0.000000   \n",
       "17                                    0.000000   \n",
       "18                                  116.057986   \n",
       "19                                   32.599560   \n",
       "20                                  131.801319   \n",
       "21                                  129.968160   \n",
       "22                                    0.000000   \n",
       "23                                  486.915231   \n",
       "24                                  364.348611   \n",
       "25                                    0.000000   \n",
       "26                                  542.437396   \n",
       "27                                   26.321782   \n",
       "28                                   90.358218   \n",
       "29                                  487.886019   \n",
       "...                                        ...   \n",
       "1601                                156.941539   \n",
       "1602                                  0.000000   \n",
       "1603                                169.143218   \n",
       "1604                                314.789907   \n",
       "1605                                116.724583   \n",
       "1606                                125.638819   \n",
       "1607                                  0.000000   \n",
       "1608                               1912.394873   \n",
       "1609                                369.507315   \n",
       "1610                                  0.000000   \n",
       "1611                                334.641759   \n",
       "1612                                515.844769   \n",
       "1613                                 37.674549   \n",
       "1614                                 84.409167   \n",
       "1615                                558.961759   \n",
       "1616                                  3.952766   \n",
       "1617                                154.612060   \n",
       "1618                                156.692593   \n",
       "1619                                  0.000000   \n",
       "1620                                415.173854   \n",
       "1621                                470.938970   \n",
       "1622                                 58.021331   \n",
       "1623                                 61.246644   \n",
       "1624                                  0.000000   \n",
       "1625                                182.852870   \n",
       "1626                                240.632060   \n",
       "1627                                 49.641481   \n",
       "1628                                105.348530   \n",
       "1629                                 20.693403   \n",
       "1630                                 81.649005   \n",
       "\n",
       "      requester_days_since_first_post_on_raop_at_request  \\\n",
       "0                                              0.000000    \n",
       "1                                              0.000000    \n",
       "2                                              0.000000    \n",
       "3                                              0.000000    \n",
       "4                                              0.000000    \n",
       "5                                             44.114606    \n",
       "6                                              0.000000    \n",
       "7                                              0.000000    \n",
       "8                                              0.000000    \n",
       "9                                              0.000000    \n",
       "10                                             0.000000    \n",
       "11                                             0.000000    \n",
       "12                                             0.000000    \n",
       "13                                             0.000000    \n",
       "14                                             6.011111    \n",
       "15                                             0.000000    \n",
       "16                                             0.000000    \n",
       "17                                             0.000000    \n",
       "18                                             9.813275    \n",
       "19                                             0.799583    \n",
       "20                                             0.000000    \n",
       "21                                            75.894201    \n",
       "22                                             0.000000    \n",
       "23                                           178.024005    \n",
       "24                                             0.000000    \n",
       "25                                             0.000000    \n",
       "26                                             0.000000    \n",
       "27                                             0.087813    \n",
       "28                                             0.000000    \n",
       "29                                           321.217477    \n",
       "...                                                 ...    \n",
       "1601                                         138.401910    \n",
       "1602                                           0.000000    \n",
       "1603                                           0.000000    \n",
       "1604                                           0.000000    \n",
       "1605                                           0.000000    \n",
       "1606                                           0.000000    \n",
       "1607                                           0.000000    \n",
       "1608                                           0.000000    \n",
       "1609                                           0.000000    \n",
       "1610                                           0.000000    \n",
       "1611                                          22.776782    \n",
       "1612                                           0.000000    \n",
       "1613                                          35.733275    \n",
       "1614                                           0.000000    \n",
       "1615                                           0.000000    \n",
       "1616                                           0.000000    \n",
       "1617                                           0.000000    \n",
       "1618                                           0.000000    \n",
       "1619                                           0.000000    \n",
       "1620                                           0.000000    \n",
       "1621                                           0.000000    \n",
       "1622                                           0.000000    \n",
       "1623                                           0.000000    \n",
       "1624                                           0.000000    \n",
       "1625                                           0.000000    \n",
       "1626                                           0.000000    \n",
       "1627                                           0.000000    \n",
       "1628                                           0.000000    \n",
       "1629                                           0.000000    \n",
       "1630                                           0.000000    \n",
       "\n",
       "      requester_number_of_comments_at_request  \\\n",
       "0                                          57   \n",
       "1                                         145   \n",
       "2                                           0   \n",
       "3                                         277   \n",
       "4                                           0   \n",
       "5                                         418   \n",
       "6                                           2   \n",
       "7                                          42   \n",
       "8                                           1   \n",
       "9                                         625   \n",
       "10                                        443   \n",
       "11                                         12   \n",
       "12                                         41   \n",
       "13                                        109   \n",
       "14                                        108   \n",
       "15                                         41   \n",
       "16                                          0   \n",
       "17                                          0   \n",
       "18                                         99   \n",
       "19                                         26   \n",
       "20                                          4   \n",
       "21                                        130   \n",
       "22                                          0   \n",
       "23                                          0   \n",
       "24                                          0   \n",
       "25                                          0   \n",
       "26                                        524   \n",
       "27                                         82   \n",
       "28                                          0   \n",
       "29                                        956   \n",
       "...                                       ...   \n",
       "1601                                       21   \n",
       "1602                                        0   \n",
       "1603                                        6   \n",
       "1604                                      120   \n",
       "1605                                      138   \n",
       "1606                                       57   \n",
       "1607                                        0   \n",
       "1608                                      992   \n",
       "1609                                       51   \n",
       "1610                                        0   \n",
       "1611                                      562   \n",
       "1612                                      338   \n",
       "1613                                        8   \n",
       "1614                                        0   \n",
       "1615                                      158   \n",
       "1616                                       56   \n",
       "1617                                        2   \n",
       "1618                                      101   \n",
       "1619                                        0   \n",
       "1620                                      512   \n",
       "1621                                        0   \n",
       "1622                                        0   \n",
       "1623                                        2   \n",
       "1624                                        0   \n",
       "1625                                       13   \n",
       "1626                                       21   \n",
       "1627                                       92   \n",
       "1628                                      261   \n",
       "1629                                        8   \n",
       "1630                                        5   \n",
       "\n",
       "      requester_number_of_comments_in_raop_at_request  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "5                                                   2   \n",
       "6                                                   0   \n",
       "7                                                   0   \n",
       "8                                                   0   \n",
       "9                                                   0   \n",
       "10                                                  0   \n",
       "11                                                  0   \n",
       "12                                                  0   \n",
       "13                                                  0   \n",
       "14                                                  1   \n",
       "15                                                  0   \n",
       "16                                                  0   \n",
       "17                                                  0   \n",
       "18                                                  2   \n",
       "19                                                  2   \n",
       "20                                                  0   \n",
       "21                                                  0   \n",
       "22                                                  0   \n",
       "23                                                  0   \n",
       "24                                                  0   \n",
       "25                                                  0   \n",
       "26                                                  0   \n",
       "27                                                  5   \n",
       "28                                                  0   \n",
       "29                                                  1   \n",
       "...                                               ...   \n",
       "1601                                                3   \n",
       "1602                                                0   \n",
       "1603                                                0   \n",
       "1604                                                0   \n",
       "1605                                                0   \n",
       "1606                                                0   \n",
       "1607                                                0   \n",
       "1608                                                0   \n",
       "1609                                                0   \n",
       "1610                                                0   \n",
       "1611                                                1   \n",
       "1612                                                0   \n",
       "1613                                                1   \n",
       "1614                                                0   \n",
       "1615                                                0   \n",
       "1616                                                0   \n",
       "1617                                                0   \n",
       "1618                                                0   \n",
       "1619                                                0   \n",
       "1620                                                0   \n",
       "1621                                                0   \n",
       "1622                                                0   \n",
       "1623                                                0   \n",
       "1624                                                0   \n",
       "1625                                                0   \n",
       "1626                                                0   \n",
       "1627                                                0   \n",
       "1628                                                0   \n",
       "1629                                                0   \n",
       "1630                                                0   \n",
       "\n",
       "      requester_number_of_posts_at_request  \\\n",
       "0                                       10   \n",
       "1                                       36   \n",
       "2                                        0   \n",
       "3                                       17   \n",
       "4                                        0   \n",
       "5                                      117   \n",
       "6                                        2   \n",
       "7                                       11   \n",
       "8                                        0   \n",
       "9                                      129   \n",
       "10                                      85   \n",
       "11                                       1   \n",
       "12                                       6   \n",
       "13                                       6   \n",
       "14                                      48   \n",
       "15                                       6   \n",
       "16                                       0   \n",
       "17                                       0   \n",
       "18                                      24   \n",
       "19                                       2   \n",
       "20                                       2   \n",
       "21                                      66   \n",
       "22                                       0   \n",
       "23                                      48   \n",
       "24                                     139   \n",
       "25                                       0   \n",
       "26                                       6   \n",
       "27                                       9   \n",
       "28                                      15   \n",
       "29                                      22   \n",
       "...                                    ...   \n",
       "1601                                     8   \n",
       "1602                                     0   \n",
       "1603                                     6   \n",
       "1604                                     7   \n",
       "1605                                    59   \n",
       "1606                                    11   \n",
       "1607                                     0   \n",
       "1608                                    29   \n",
       "1609                                     6   \n",
       "1610                                     0   \n",
       "1611                                    46   \n",
       "1612                                     6   \n",
       "1613                                     4   \n",
       "1614                                    15   \n",
       "1615                                    37   \n",
       "1616                                     4   \n",
       "1617                                     0   \n",
       "1618                                    12   \n",
       "1619                                     0   \n",
       "1620                                    56   \n",
       "1621                                    60   \n",
       "1622                                    24   \n",
       "1623                                     0   \n",
       "1624                                     0   \n",
       "1625                                     0   \n",
       "1626                                     7   \n",
       "1627                                     5   \n",
       "1628                                    30   \n",
       "1629                                     1   \n",
       "1630                                     2   \n",
       "\n",
       "      requester_number_of_posts_on_raop_at_request  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "5                                                0   \n",
       "6                                                0   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "9                                                0   \n",
       "10                                               0   \n",
       "11                                               0   \n",
       "12                                               0   \n",
       "13                                               0   \n",
       "14                                               0   \n",
       "15                                               0   \n",
       "16                                               0   \n",
       "17                                               0   \n",
       "18                                               0   \n",
       "19                                               1   \n",
       "20                                               0   \n",
       "21                                               2   \n",
       "22                                               0   \n",
       "23                                               1   \n",
       "24                                               0   \n",
       "25                                               0   \n",
       "26                                               0   \n",
       "27                                               0   \n",
       "28                                               0   \n",
       "29                                               0   \n",
       "...                                            ...   \n",
       "1601                                             0   \n",
       "1602                                             0   \n",
       "1603                                             0   \n",
       "1604                                             0   \n",
       "1605                                             0   \n",
       "1606                                             0   \n",
       "1607                                             0   \n",
       "1608                                             0   \n",
       "1609                                             0   \n",
       "1610                                             0   \n",
       "1611                                             0   \n",
       "1612                                             0   \n",
       "1613                                             0   \n",
       "1614                                             0   \n",
       "1615                                             0   \n",
       "1616                                             0   \n",
       "1617                                             0   \n",
       "1618                                             0   \n",
       "1619                                             0   \n",
       "1620                                             0   \n",
       "1621                                             0   \n",
       "1622                                             0   \n",
       "1623                                             0   \n",
       "1624                                             0   \n",
       "1625                                             0   \n",
       "1626                                             0   \n",
       "1627                                             0   \n",
       "1628                                             0   \n",
       "1629                                             0   \n",
       "1630                                             0   \n",
       "\n",
       "      requester_number_of_subreddits_at_request  \\\n",
       "0                                            16   \n",
       "1                                            29   \n",
       "2                                             0   \n",
       "3                                            30   \n",
       "4                                             0   \n",
       "5                                            41   \n",
       "6                                             3   \n",
       "7                                            14   \n",
       "8                                             1   \n",
       "9                                            72   \n",
       "10                                           46   \n",
       "11                                            6   \n",
       "12                                           10   \n",
       "13                                            6   \n",
       "14                                           31   \n",
       "15                                            7   \n",
       "16                                            0   \n",
       "17                                            0   \n",
       "18                                           22   \n",
       "19                                           13   \n",
       "20                                            2   \n",
       "21                                            8   \n",
       "22                                            0   \n",
       "23                                           27   \n",
       "24                                           27   \n",
       "25                                            0   \n",
       "26                                           34   \n",
       "27                                            6   \n",
       "28                                            6   \n",
       "29                                           27   \n",
       "...                                         ...   \n",
       "1601                                         15   \n",
       "1602                                          0   \n",
       "1603                                          8   \n",
       "1604                                         22   \n",
       "1605                                         18   \n",
       "1606                                         16   \n",
       "1607                                          0   \n",
       "1608                                         83   \n",
       "1609                                         13   \n",
       "1610                                          0   \n",
       "1611                                         67   \n",
       "1612                                          6   \n",
       "1613                                          8   \n",
       "1614                                         10   \n",
       "1615                                         24   \n",
       "1616                                         19   \n",
       "1617                                          2   \n",
       "1618                                          8   \n",
       "1619                                          0   \n",
       "1620                                         36   \n",
       "1621                                         11   \n",
       "1622                                         19   \n",
       "1623                                          2   \n",
       "1624                                          0   \n",
       "1625                                          6   \n",
       "1626                                         11   \n",
       "1627                                         13   \n",
       "1628                                         22   \n",
       "1629                                          5   \n",
       "1630                                          4   \n",
       "\n",
       "                        requester_subreddits_at_request  \\\n",
       "0     [AskReddit, COents, Denver, DenverBroncos, Lib...   \n",
       "1     [Android, AskReddit, GrandTheftAutoV, IAmA, Mi...   \n",
       "2                                                    []   \n",
       "3     [AdviceAnimals, Art, AskReddit, GetMotivated, ...   \n",
       "4                                                    []   \n",
       "5     [Art, AskReddit, FIFA12, FantasyPL, IAmA, Life...   \n",
       "6           [Random_Acts_Of_Pizza, atheism, technology]   \n",
       "7     [AnimalPorn, AskReddit, Music, Random_Acts_Of_...   \n",
       "8                                                [IAmA]   \n",
       "9     [Anarchism, AnarchistNews, Anarcho_Capitalism,...   \n",
       "10    [Android, AskReddit, Boobies, Dredmor, EmmaWat...   \n",
       "11        [AskReddit, Music, WTF, aww, deftones, funny]   \n",
       "12    [AdviceAnimals, Gunsforsale, answers, bestoftr...   \n",
       "13    [NoFap, ValhallaChallenge, WTF, asmr, baseball...   \n",
       "14    [AskReddit, BobNewhart, FreeKarma, Hawkman, Lu...   \n",
       "15    [AskReddit, IAmA, Music, PostHardcore, Sinfoni...   \n",
       "16                                                   []   \n",
       "17                                                   []   \n",
       "18    [AskReddit, CityOfLA, DoesAnybodyElse, IAmA, L...   \n",
       "19    [AskReddit, IAmA, Random_Acts_Of_Pizza, circle...   \n",
       "20                            [gaming, leagueoflegends]   \n",
       "21    [Random_Acts_Of_Amazon, Random_Acts_Of_Pizza, ...   \n",
       "22                                                   []   \n",
       "23    [AdviceAnimals, ArcherFX, AskReddit, Boxing, D...   \n",
       "24    [AdviceAnimals, AskReddit, Bass, Dogfort, Frug...   \n",
       "25                                                   []   \n",
       "26    [AdviceAnimals, AmateurArchives, AsianHotties,...   \n",
       "27    [LadyBoners, MakeupAddiction, Random_Acts_Of_P...   \n",
       "28    [AskReddit, deadisland, gaming, hockey, loseit...   \n",
       "29    [AskReddit, Dexter, DoesAnybodyElse, IAmA, Let...   \n",
       "...                                                 ...   \n",
       "1601  [AskReddit, AtheismComingOut, BoyScouts, Color...   \n",
       "1602                                                 []   \n",
       "1603  [DrunkTank, Guitar, Random_Acts_Of_Pizza, blue...   \n",
       "1604  [AdviceAnimals, AskReddit, IAmA, Music, WTF, W...   \n",
       "1605  [AdviceAnimals, Android, GoneWildPlus, IAmA, a...   \n",
       "1606  [AdviceAnimals, AskReddit, IAmA, MakeupAddicti...   \n",
       "1607                                                 []   \n",
       "1608  [4chan, AdviceAnimals, Android, AskReddit, Bac...   \n",
       "1609  [AskReddit, Baking, FilmIndustryLA, LearnJapan...   \n",
       "1610                                                 []   \n",
       "1611  [Advice, AdviceAnimals, AmISexy, AskReddit, Bo...   \n",
       "1612      [BostonBruins, IAmA, aww, hockey, nhl, trees]   \n",
       "1613  [AskSocialScience, RandomActsOfCookies, Random...   \n",
       "1614  [Android, AskReddit, Dreams, funny, ihaveissue...   \n",
       "1615  [AskReddit, Blink182, Diablo, FinalFantasy, Gu...   \n",
       "1616  [AskReddit, Borderlands, Borderlands2, IAmA, M...   \n",
       "1617                  [Random_Acts_Of_Pizza, starcraft]   \n",
       "1618  [AdviceAnimals, AskReddit, IAmA, SquaredCircle...   \n",
       "1619                                                 []   \n",
       "1620  [AdviceAnimals, AirForce, AskReddit, Fitness, ...   \n",
       "1621  [AskReddit, Denver, Economics, WTF, boulder, d...   \n",
       "1622  [ArtHistory, AskElectronics, AskReddit, Minecr...   \n",
       "1623                                [offmychest, trees]   \n",
       "1624                                                 []   \n",
       "1625  [LondonSocialClub, androiddev, cpp, java, lond...   \n",
       "1626  [AskReddit, Austria, IAmA, gameofthrones, game...   \n",
       "1627  [AskReddit, AskWomen, IAmA, LetsNotMeet, Modes...   \n",
       "1628  [AskReddit, IAmA, Monterrey, ads, beermoney, b...   \n",
       "1629  [AskReddit, Austin, DoesAnybodyElse, IAmA, Ran...   \n",
       "1630  [DoesAnybodyElse, IAmA, LadyBoners, Random_Act...   \n",
       "\n",
       "      requester_upvotes_minus_downvotes_at_request  \\\n",
       "0                                              364   \n",
       "1                                              516   \n",
       "2                                                0   \n",
       "3                                             1058   \n",
       "4                                                0   \n",
       "5                                             6331   \n",
       "6                                                7   \n",
       "7                                              176   \n",
       "8                                                0   \n",
       "9                                             2796   \n",
       "10                                            2464   \n",
       "11                                              52   \n",
       "12                                             193   \n",
       "13                                             582   \n",
       "14                                            1265   \n",
       "15                                              96   \n",
       "16                                               0   \n",
       "17                                               0   \n",
       "18                                            2650   \n",
       "19                                              38   \n",
       "20                                              -1   \n",
       "21                                            1671   \n",
       "22                                               0   \n",
       "23                                            1895   \n",
       "24                                            1927   \n",
       "25                                               0   \n",
       "26                                            2326   \n",
       "27                                             533   \n",
       "28                                              34   \n",
       "29                                           11465   \n",
       "...                                            ...   \n",
       "1601                                           698   \n",
       "1602                                             0   \n",
       "1603                                            28   \n",
       "1604                                           665   \n",
       "1605                                           637   \n",
       "1606                                          1773   \n",
       "1607                                             0   \n",
       "1608                                          4580   \n",
       "1609                                           183   \n",
       "1610                                             0   \n",
       "1611                                          5205   \n",
       "1612                                          2367   \n",
       "1613                                            64   \n",
       "1614                                           101   \n",
       "1615                                           410   \n",
       "1616                                           329   \n",
       "1617                                            10   \n",
       "1618                                           210   \n",
       "1619                                             0   \n",
       "1620                                          6065   \n",
       "1621                                           844   \n",
       "1622                                           946   \n",
       "1623                                             3   \n",
       "1624                                             0   \n",
       "1625                                            22   \n",
       "1626                                           687   \n",
       "1627                                          2094   \n",
       "1628                                          1109   \n",
       "1629                                            16   \n",
       "1630                                            79   \n",
       "\n",
       "      requester_upvotes_plus_downvotes_at_request   requester_username  \\\n",
       "0                                             840               j_like   \n",
       "1                                            1448     0110110101101100   \n",
       "2                                               0       singledad22601   \n",
       "3                                            2062             Neuronut   \n",
       "4                                               0       so_damn_hungry   \n",
       "5                                           31919             leiferic   \n",
       "6                                              27         cafepressguy   \n",
       "7                                             286           javilopez1   \n",
       "8                                               6       RosyGraymalkin   \n",
       "9                                            5186  vomitisjustskimmilk   \n",
       "10                                           5494                txtsd   \n",
       "11                                             70       DrunkenPopTart   \n",
       "12                                            397              Java980   \n",
       "13                                            740          darthfapper   \n",
       "14                                           2095              stegogo   \n",
       "15                                            142        ASD_Sinfonian   \n",
       "16                                              0  Littleworldbigheart   \n",
       "17                                              0     fudging_starving   \n",
       "18                                          14450              Trioxin   \n",
       "19                                             56       leftyguitarguy   \n",
       "20                                             25         lolcatcatlol   \n",
       "21                                           1941          wildcatz311   \n",
       "22                                              0           wolfknight   \n",
       "23                                           9405     sterling_mallory   \n",
       "24                                           8773        flinteastwood   \n",
       "25                                              0        Sweetpeamommy   \n",
       "26                                           4402            deimosian   \n",
       "27                                            651       plaidsuitpants   \n",
       "28                                            176           Oosterhuis   \n",
       "29                                          23643      Totesmcgotes702   \n",
       "...                                           ...                  ...   \n",
       "1601                                         1580             dicastio   \n",
       "1602                                            0             Lucy_dog   \n",
       "1603                                           68        PeterMacIrish   \n",
       "1604                                         1115       numberthirteen   \n",
       "1605                                         3345         williambueti   \n",
       "1606                                         3171     FlaxwenchPromise   \n",
       "1607                                            0           YepImBroke   \n",
       "1608                                         7500              Xeiliex   \n",
       "1609                                          269            etiolates   \n",
       "1610                                            0        ShludleDoodle   \n",
       "1611                                        12951     bananaslughippie   \n",
       "1612                                         3327          FlyingCouch   \n",
       "1613                                          100               Krissp   \n",
       "1614                                          331     AwesomeIncarnate   \n",
       "1615                                          710     HayleyWearsPrada   \n",
       "1616                                          449           Kincade117   \n",
       "1617                                           10                Kappn   \n",
       "1618                                          466        Foley_is_Good   \n",
       "1619                                            0             msmunn87   \n",
       "1620                                        56809        chinchilla618   \n",
       "1621                                         2356          Colorado222   \n",
       "1622                                         7158       withoutamartyr   \n",
       "1623                                            3    KindOfWatchingYou   \n",
       "1624                                            0        theniceiceman   \n",
       "1625                                           30           SomniSmith   \n",
       "1626                                         2079               post91   \n",
       "1627                                         2876         AccioNeedles   \n",
       "1628                                         6689              ivanbco   \n",
       "1629                                           24              table95   \n",
       "1630                                          123            Clurshank   \n",
       "\n",
       "      unix_timestamp_of_request  unix_timestamp_of_request_utc  \n",
       "0                    1308963419                     1308959819  \n",
       "1                    1379263523                     1379259923  \n",
       "2                    1318636421                     1318632821  \n",
       "3                    1375220282                     1375216682  \n",
       "4                    1335934358                     1335930758  \n",
       "5                    1329601990                     1329601990  \n",
       "6                    1354312678                     1354312678  \n",
       "7                    1359831611                     1359831611  \n",
       "8                    1377933122                     1377929522  \n",
       "9                    1364268605                     1364265005  \n",
       "10                   1322035223                     1322035223  \n",
       "11                   1350854274                     1350850674  \n",
       "12                   1316524577                     1316520977  \n",
       "13                   1374556106                     1374552506  \n",
       "14                   1353195597                     1353195597  \n",
       "15                   1319072110                     1319068510  \n",
       "16                   1344477471                     1344473871  \n",
       "17                   1316737639                     1316734039  \n",
       "18                   1310154205                     1310150605  \n",
       "19                   1311982380                     1311978780  \n",
       "20                   1312314486                     1312310886  \n",
       "21                   1378408533                     1378404933  \n",
       "22                   1309470238                     1309466638  \n",
       "23                   1344907515                     1344903915  \n",
       "24                   1306451174                     1306447574  \n",
       "25                   1313107673                     1313104073  \n",
       "26                   1376254795                     1376251195  \n",
       "27                   1338074026                     1338070426  \n",
       "28                   1319953020                     1319949420  \n",
       "29                   1378779268                     1378775668  \n",
       "...                         ...                            ...  \n",
       "1601                 1335078942                     1335075342  \n",
       "1602                 1347841196                     1347837596  \n",
       "1603                 1329334612                     1329334612  \n",
       "1604                 1372905658                     1372902058  \n",
       "1605                 1314790432                     1314786832  \n",
       "1606                 1371671770                     1371668170  \n",
       "1607                 1309901494                     1309897894  \n",
       "1608                 1366243905                     1366240305  \n",
       "1609                 1377637800                     1377634200  \n",
       "1610                 1340154613                     1340151013  \n",
       "1611                 1322181527                     1322181527  \n",
       "1612                 1370399740                     1370396140  \n",
       "1613                 1331931696                     1331928096  \n",
       "1614                 1319404428                     1319400828  \n",
       "1615                 1378861954                     1378858354  \n",
       "1616                 1348439756                     1348436156  \n",
       "1617                 1320946591                     1320946591  \n",
       "1618                 1377915885                     1377912285  \n",
       "1619                 1309995182                     1309991582  \n",
       "1620                 1344035842                     1344032242  \n",
       "1621                 1333309151                     1333305551  \n",
       "1622                 1317432554                     1317428954  \n",
       "1623                 1366328655                     1366325055  \n",
       "1624                 1347393775                     1347390175  \n",
       "1625                 1365192686                     1365189086  \n",
       "1626                 1316697470                     1316693870  \n",
       "1627                 1350957149                     1350953549  \n",
       "1628                 1311296237                     1311292637  \n",
       "1629                 1325444789                     1325444789  \n",
       "1630                 1359748168                     1359748168  \n",
       "\n",
       "[1631 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
